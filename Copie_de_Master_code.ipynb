{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elidonda2-web/Alisia-7B-it-/blob/main/Copie_de_Master_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_KFNebvdkjM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfkEKTUeBuN"
      },
      "source": [
        "#l'acces token que tu avais copier, colle sa dans login(\"sa doit etre √† l'int√©rieur\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9HT1SYHeie4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMDIoqH691iY"
      },
      "outputs": [],
      "source": [
        "# üì¶ Installation des d√©pendances\n",
        "#!pip install -q unsloth torch transformers trl datasets accelerate bitsandbytes\n",
        "!pip install -q gdown\n",
        "\n",
        "# üîß Importations et configuration\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import gdown\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from google.colab import drive\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# =======================\n",
        "# üîπ Configuration Principale\n",
        "# =======================\n",
        "class Config:\n",
        "    # Mod√®le et donn√©es\n",
        "    BASE_MODEL = \"Gems234/Alisia-7B-it-V1.0\"\n",
        "    DATASET_NAME = \"HuggingFaceH4/ultrachat_200k\"\n",
        "\n",
        "    # Objectifs d'entra√Ænement\n",
        "    TOTAL_DATASET_SIZE = 50000\n",
        "    TARGET_COVERAGE = 20000  # 20% de 100k\n",
        "    EXAMPLES_PER_SESSION = 336  # 84 steps √ó 4 grad_accum\n",
        "\n",
        "    # Param√®tres techniques\n",
        "    MAX_SEQ_LENGTH = 2048\n",
        "    LOAD_IN_4BIT = True\n",
        "    DTYPE = None\n",
        "    PER_DEVICE_BATCH = 2\n",
        "    GRAD_ACCUM = 4\n",
        "    MAX_STEPS = 84\n",
        "    LEARNING_RATE = 2e-4\n",
        "    SEED = 3407\n",
        "\n",
        "    # Chemins\n",
        "    WORK_DIR = \"/content/alisia_collab\"\n",
        "    DRIVE_MOUNT = \"/content/drive\"\n",
        "    DRIVE_BASE_PATH = \"/content/drive/MyDrive/Alisia_Collab\"\n",
        "    SOURCES_FILE = \"sources.json\"\n",
        "    LOCK_TIMEOUT_HOURS = 6\n",
        "\n",
        "    # === SOURCES COLLABORATIVES COMPL√àTES ===\n",
        "    MANUAL_SOURCES = {\n",
        "        \"√âlie\": \"https://drive.google.com/drive/folders/1ndS1XHWkcTp57s1wibxYIH4P_KB6elsw\",\n",
        "        \"Jos\":\"https://drive.google.com/drive/folders/1bw9J5goW1GzT1O7MA2vA0_BC-wAiiVGE\"\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# üìÅ Montage Google Drive\n",
        "def setup_drive():\n",
        "    \"\"\"Monte Google Drive et cr√©e la structure de dossiers\"\"\"\n",
        "    #print(\"üìÅ Montage de Google Drive...\")\n",
        "    #drive.mount(config.DRIVE_MOUNT)\n",
        "\n",
        "    # Cr√©er le dossier de base si n√©cessaire\n",
        "    os.makedirs(config.DRIVE_BASE_PATH, exist_ok=True)\n",
        "    print(f\"‚úÖ Drive mont√©: {config.DRIVE_BASE_PATH}\")\n",
        "\n",
        "setup_drive()\n",
        "\n",
        "# üîó FONCTION load_sources DOIT √äTRE D√âFINIE AVANT get_user_identity()\n",
        "def load_sources():\n",
        "    \"\"\"Charge ou initialise le fichier sources.json avec la nouvelle structure\"\"\"\n",
        "    sources_path = os.path.join(config.DRIVE_BASE_PATH, config.SOURCES_FILE)\n",
        "\n",
        "    if os.path.exists(sources_path):\n",
        "        with open(sources_path, \"r\") as f:\n",
        "            sources = json.load(f)\n",
        "\n",
        "        # V√©rifier la structure et migrer si n√©cessaire\n",
        "        sources = migrate_sources_structure(sources)\n",
        "        return sources\n",
        "    else:\n",
        "        # Nouvelle structure avec scores\n",
        "        initial_sources = {\n",
        "            \"participants\": {},\n",
        "            \"metadata\": {\n",
        "                \"created\": datetime.now().isoformat(),\n",
        "                \"total_sessions\": 0,\n",
        "                \"last_training_user\": None,\n",
        "                \"best_performer\": None,\n",
        "                \"total_collective_steps\": 0,\n",
        "                \"dernier_termine\": None,\n",
        "                \"heure_dernier_termine\": None,\n",
        "                \"session_id\": 0\n",
        "            },\n",
        "            \"training_rotation\": []\n",
        "        }\n",
        "        save_sources(initial_sources)\n",
        "        print(\"üìÅ Fichier sources.json cr√©√© avec nouvelle structure\")\n",
        "        return initial_sources\n",
        "\n",
        "def save_sources(sources):\n",
        "    \"\"\"Sauvegarde le fichier sources.json\"\"\"\n",
        "    sources_path = os.path.join(config.DRIVE_BASE_PATH, config.SOURCES_FILE)\n",
        "    with open(sources_path, \"w\") as f:\n",
        "        json.dump(sources, f, indent=2)\n",
        "\n",
        "def migrate_sources_structure(sources):\n",
        "    \"\"\"Migre l'ancienne structure vers la nouvelle\"\"\"\n",
        "    print(\"üîÑ Migration automatique de sources.json...\")\n",
        "\n",
        "    if \"participants\" in sources:\n",
        "        for user_name, user_data in sources[\"participants\"].items():\n",
        "            # Ajouter les champs manquants\n",
        "            if \"user_id\" not in user_data:\n",
        "                user_data[\"user_id\"] = generate_user_id(sources)\n",
        "                print(f\"   ‚úÖ ID g√©n√©r√© pour {user_name}: {user_data['user_id']}\")\n",
        "            if \"total_steps\" not in user_data:\n",
        "                user_data[\"total_steps\"] = 0\n",
        "            if \"performance_score\" not in user_data:\n",
        "                user_data[\"performance_score\"] = 0.0\n",
        "            if \"last_activity\" not in user_data:\n",
        "                user_data[\"last_activity\"] = datetime.now().isoformat()\n",
        "\n",
        "    if \"metadata\" not in sources:\n",
        "        sources[\"metadata\"] = {\n",
        "            \"created\": datetime.now().isoformat(),\n",
        "            \"total_sessions\": 0,\n",
        "            \"last_training_user\": None,\n",
        "            \"best_performer\": None,\n",
        "            \"total_collective_steps\": 0\n",
        "        }\n",
        "\n",
        "    # üè∑ AJOUTER LES CHAMPS √âTIQUETTE SI ABSENTS\n",
        "    if \"dernier_termine\" not in sources[\"metadata\"]:\n",
        "        sources[\"metadata\"][\"dernier_termine\"] = None\n",
        "        sources[\"metadata\"][\"heure_dernier_termine\"] = None\n",
        "        sources[\"metadata\"][\"session_id\"] = 0\n",
        "\n",
        "    # üõ†Ô∏è CORRECTION : S'ASSURER QUE total_collective_steps EXISTE\n",
        "    if \"total_collective_steps\" not in sources[\"metadata\"]:\n",
        "        sources[\"metadata\"][\"total_collective_steps\"] = 0\n",
        "\n",
        "    if \"training_rotation\" not in sources:\n",
        "        sources[\"training_rotation\"] = []\n",
        "\n",
        "    save_sources(sources)\n",
        "    print(\"‚úÖ Structure de sources.json migr√©e\")\n",
        "    return sources\n",
        "\n",
        "def generate_user_id(sources):\n",
        "    \"\"\"G√©n√®re un ID utilisateur unique\"\"\"\n",
        "    existing_ids = [user_data.get(\"user_id\", \"\") for user_data in sources[\"participants\"].values() if user_data.get(\"user_id\")]\n",
        "    new_id = str(len(existing_ids) + 1)\n",
        "    while new_id in existing_ids:\n",
        "        new_id = str(int(new_id) + 1)\n",
        "    return new_id\n",
        "\n",
        "# üë§ MAINTENANT on peut d√©finir get_user_identity()\n",
        "def get_user_identity():\n",
        "    \"\"\"Identifie l'utilisateur avec g√©n√©ration d'ID unique\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    print(\"üë§ Syst√®me d'identification collaboratif\")\n",
        "    print(\"1. Nouvel utilisateur\")\n",
        "    print(\"2. Utilisateur existant\")\n",
        "\n",
        "    choice = input(\"Choisissez une option (1 ou 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Nouvel utilisateur\n",
        "        user_name = input(\"Entrez votre nom: \").strip()\n",
        "\n",
        "        # V√©rifier si le nom existe d√©j√†\n",
        "        if user_name in sources[\"participants\"]:\n",
        "            print(\"‚ùå Ce nom existe d√©j√†\")\n",
        "            return get_user_identity()\n",
        "\n",
        "        user_id = generate_user_id(sources)\n",
        "\n",
        "        # Enregistrer le nouvel utilisateur\n",
        "        sources[\"participants\"][user_name] = {\n",
        "            \"user_id\": user_id,\n",
        "            \"drive_url\": \"\",\n",
        "            \"added_date\": datetime.now().isoformat(),\n",
        "            \"sessions_completed\": 0,\n",
        "            \"total_steps\": 0,\n",
        "            \"last_activity\": datetime.now().isoformat(),\n",
        "            \"performance_score\": 0.0\n",
        "        }\n",
        "        save_sources(sources)\n",
        "        print(f\"‚úÖ Nouvel utilisateur cr√©√©: {user_name} (ID: {user_id})\")\n",
        "\n",
        "    else:\n",
        "        # Utilisateur existant - CORRECTION ICI\n",
        "        user_name = input(\"Entrez votre nom: \").strip()\n",
        "        if user_name in sources[\"participants\"]:\n",
        "            # üõ†Ô∏è CORRECTION : V√©rifier si user_id existe, sinon le g√©n√©rer\n",
        "            user_data = sources[\"participants\"][user_name]\n",
        "            if \"user_id\" not in user_data:\n",
        "                user_data[\"user_id\"] = generate_user_id(sources)\n",
        "                save_sources(sources)\n",
        "                print(f\"üÜï ID g√©n√©r√© pour {user_name}: {user_data['user_id']}\")\n",
        "\n",
        "            user_id = user_data[\"user_id\"]\n",
        "            print(f\"‚úÖ Utilisateur reconnu: {user_name} (ID: {user_id})\")\n",
        "        else:\n",
        "            print(\"‚ùå Utilisateur non trouv√©\")\n",
        "            return get_user_identity()\n",
        "\n",
        "    return user_id, user_name\n",
        "\n",
        "user_id, user_name = get_user_identity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLDg82g9PoFE"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(ranges, tokenizer):\n",
        "    \"\"\"Charge les tranches de dataset et applique le format de conversation\"\"\"\n",
        "    if not isinstance(ranges, (list, tuple)):\n",
        "        raise ValueError(\"‚ùå 'ranges' doit √™tre une liste de tuples (start, end)\")\n",
        "\n",
        "    loaded_slices = []\n",
        "    for s, e in ranges:\n",
        "        slice_expr = f\"train_sft[{s}:{e}]\"\n",
        "        print(f\"üì• Chargement: {slice_expr}\")\n",
        "        ds_part = load_dataset(config.DATASET_NAME, split=slice_expr)\n",
        "        loaded_slices.append(ds_part)\n",
        "\n",
        "    if len(loaded_slices) == 1:\n",
        "        dataset = loaded_slices[0]\n",
        "    else:\n",
        "        dataset = concatenate_datasets(loaded_slices)\n",
        "        print(f\"üîó {len(loaded_slices)} tranches concat√©n√©es -> {len(dataset)} exemples\")\n",
        "\n",
        "    tokenizer.chat_template = \"\"\"<|im_start|>system\n",
        "You are Alisia, a helpful, precise, and knowledgeable assistant created by the Alisia Research Team.<|im_end|>\n",
        "{% for message in messages %}\n",
        "<|im_start|>{{ message['role'] }}\n",
        "{{ message['content'] }}<|im_end|>\n",
        "{% endfor %}\n",
        "{% if add_generation_prompt %}<|im_start|>assistant\n",
        "{% endif %}\"\"\"\n",
        "\n",
        "    def formatting_prompts_func(examples):\n",
        "        conversations = examples[\"messages\"]\n",
        "        texts = [\n",
        "            tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
        "            for convo in conversations\n",
        "        ]\n",
        "        return {\"text\": texts}\n",
        "\n",
        "    dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "    print(f\"‚úÖ Dataset pr√™t pour entra√Ænement : {len(dataset)} exemples\")\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH4vRtZfPtEh"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# SYST√àME COLLABORATIF COMPLET CORRIG√â\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import shutil\n",
        "import gdown\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- V√©rifications pr√©alables s√©curis√©es ---\n",
        "def verify_dependencies():\n",
        "    \"\"\"V√©rifie toutes les d√©pendances de mani√®re s√©curis√©e\"\"\"\n",
        "    missing = []\n",
        "\n",
        "    # V√©rification des imports critiques\n",
        "    try:\n",
        "        from unsloth import FastLanguageModel\n",
        "    except ImportError:\n",
        "        missing.append(\"unsloth\")\n",
        "\n",
        "    try:\n",
        "        from trl import SFTConfig, SFTTrainer\n",
        "    except ImportError:\n",
        "        missing.append(\"trl\")\n",
        "\n",
        "    try:\n",
        "        from transformers import DataCollatorForSeq2Seq\n",
        "    except ImportError:\n",
        "        missing.append(\"transformers\")\n",
        "\n",
        "    # V√©rification des fonctions d√©finies\n",
        "    if \"prepare_dataset\" not in globals():\n",
        "        missing.append(\"prepare_dataset (d√©fini en cellule 2)\")\n",
        "\n",
        "    if missing:\n",
        "        print(\"‚ùå D√©pendances manquantes :\")\n",
        "        for m in missing:\n",
        "            print(f\"   - {m}\")\n",
        "        print(\"\\nüì¶ Installation recommand√©e :\")\n",
        "        print(\"!pip install -q unsloth trl transformers bitsandbytes accelerate datasets gdown\")\n",
        "        return False\n",
        "\n",
        "    print(\"‚úÖ Toutes les d√©pendances sont disponibles\")\n",
        "    return True\n",
        "\n",
        "# --- Configuration s√©curis√©e ---\n",
        "class SafeConfig:\n",
        "    \"\"\"Configuration avec valeurs par d√©faut s√©curis√©es\"\"\"\n",
        "    # Chemins\n",
        "    DRIVE_BASE_PATH = getattr(config, 'DRIVE_BASE_PATH', '/content/drive')\n",
        "    WORK_DIR = getattr(config, 'WORK_DIR', '/content')\n",
        "    SOURCES_FILE = getattr(config, 'SOURCES_FILE', 'sources.json')\n",
        "\n",
        "    # Mod√®le\n",
        "    BASE_MODEL = getattr(config, 'BASE_MODEL', 'Gems234/Alisia-7B-it-V1.0')\n",
        "    MAX_SEQ_LENGTH = getattr(config, 'MAX_SEQ_LENGTH', 2048)\n",
        "    DTYPE = getattr(config, 'DTYPE', None)\n",
        "    LOAD_IN_4BIT = getattr(config, 'LOAD_IN_4BIT', True)\n",
        "\n",
        "    # Entra√Ænement\n",
        "    MAX_STEPS = getattr(config, 'MAX_STEPS', 100)\n",
        "    LEARNING_RATE = getattr(config, 'LEARNING_RATE', 2e-4)\n",
        "    PER_DEVICE_BATCH = getattr(config, 'PER_DEVICE_BATCH', 1)\n",
        "    GRAD_ACCUM = getattr(config, 'GRAD_ACCUM', 1)\n",
        "    SEED = getattr(config, 'SEED', 42)\n",
        "\n",
        "    # Dataset\n",
        "    EXAMPLES_PER_SESSION = getattr(config, 'EXAMPLES_PER_SESSION', 100)\n",
        "    TOTAL_DATASET_SIZE = getattr(config, 'TOTAL_DATASET_SIZE', 1000)\n",
        "    TARGET_COVERAGE = getattr(config, 'TARGET_COVERAGE', 1000)\n",
        "\n",
        "    # Verrou\n",
        "    LOCK_TIMEOUT_HOURS = getattr(config, 'LOCK_TIMEOUT_HOURS', 6)\n",
        "\n",
        "    # Sources manuelles (fallback)\n",
        "    MANUAL_SOURCES = getattr(config, 'MANUAL_SOURCES', {})\n",
        "\n",
        "# --- Utilitaires atomiques ---\n",
        "def atomic_write_json(path, data):\n",
        "    \"\"\"√âcriture atomique de JSON\"\"\"\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        tmp_path = path + '.tmp'\n",
        "        with open(tmp_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "        os.replace(tmp_path, path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur √©criture atomique {path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def atomic_write_text(path, text):\n",
        "    \"\"\"√âcriture atomique de texte\"\"\"\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        tmp_path = path + '.tmp'\n",
        "        with open(tmp_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        os.replace(tmp_path, path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur √©criture texte {path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Gestion des sources et √©tiquettes ---\n",
        "def load_sources():\n",
        "    \"\"\"Charge ou initialise le fichier sources.json\"\"\"\n",
        "    sources_path = os.path.join(SafeConfig.DRIVE_BASE_PATH, SafeConfig.SOURCES_FILE)\n",
        "\n",
        "    if os.path.exists(sources_path):\n",
        "        try:\n",
        "            with open(sources_path, 'r', encoding='utf-8') as f:\n",
        "                sources = json.load(f)\n",
        "            print(\"‚úÖ Sources charg√©es depuis\", sources_path)\n",
        "            return migrate_sources_structure(sources)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur chargement sources: {e}\")\n",
        "\n",
        "    # Structure initiale\n",
        "    initial_sources = {\n",
        "        \"participants\": {},\n",
        "        \"metadata\": {\n",
        "            \"created\": datetime.now().isoformat(),\n",
        "            \"total_sessions\": 0,\n",
        "            \"last_training_user\": None,\n",
        "            \"best_performer\": None,\n",
        "            \"total_collective_steps\": 0,\n",
        "            \"dernier_termine\": None,\n",
        "            \"heure_dernier_termine\": None,\n",
        "            \"session_id\": 0\n",
        "        },\n",
        "        \"training_rotation\": []\n",
        "    }\n",
        "\n",
        "    atomic_write_json(sources_path, initial_sources)\n",
        "    print(\"üìÅ Fichier sources.json cr√©√© avec structure initiale\")\n",
        "    return initial_sources\n",
        "\n",
        "def save_sources(sources):\n",
        "    \"\"\"Sauvegarde les sources\"\"\"\n",
        "    sources_path = os.path.join(SafeConfig.DRIVE_BASE_PATH, SafeConfig.SOURCES_FILE)\n",
        "    return atomic_write_json(sources_path, sources)\n",
        "\n",
        "def migrate_sources_structure(sources):\n",
        "    \"\"\"Migre vers la nouvelle structure si n√©cessaire\"\"\"\n",
        "    if \"participants\" not in sources:\n",
        "        sources[\"participants\"] = {}\n",
        "\n",
        "    if \"metadata\" not in sources:\n",
        "        sources[\"metadata\"] = {\n",
        "            \"created\": datetime.now().isoformat(),\n",
        "            \"total_sessions\": 0,\n",
        "            \"last_training_user\": None,\n",
        "            \"best_performer\": None,\n",
        "            \"total_collective_steps\": 0\n",
        "        }\n",
        "\n",
        "    # Champs √©tiquette\n",
        "    metadata = sources[\"metadata\"]\n",
        "    if \"dernier_termine\" not in metadata:\n",
        "        metadata[\"dernier_termine\"] = None\n",
        "        metadata[\"heure_dernier_termine\"] = None\n",
        "        metadata[\"session_id\"] = 0\n",
        "\n",
        "    if \"training_rotation\" not in sources:\n",
        "        sources[\"training_rotation\"] = []\n",
        "\n",
        "    save_sources(sources)\n",
        "    return sources\n",
        "\n",
        "def generate_user_id(sources):\n",
        "    \"\"\"G√©n√®re un ID utilisateur unique\"\"\"\n",
        "    existing_ids = [data.get(\"user_id\", \"\") for data in sources[\"participants\"].values() if data.get(\"user_id\")]\n",
        "    new_id = str(len(existing_ids) + 1)\n",
        "    while new_id in existing_ids:\n",
        "        new_id = str(int(new_id) + 1)\n",
        "    return new_id\n",
        "\n",
        "def update_etiquette(user_name):\n",
        "    \"\"\"Met √† jour l'√©tiquette avec ID s√©quentiel\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    session_id = sources[\"metadata\"].get(\"session_id\", 0) + 1\n",
        "    etiquette_id = f\"{user_name}_{session_id}\"\n",
        "\n",
        "    sources[\"metadata\"][\"dernier_termine\"] = etiquette_id\n",
        "    sources[\"metadata\"][\"heure_dernier_termine\"] = datetime.now().isoformat()\n",
        "    sources[\"metadata\"][\"session_id\"] = session_id\n",
        "\n",
        "    save_sources(sources)\n",
        "    print(f\"üè∑ √âtiquette mise √† jour: {etiquette_id}\")\n",
        "    return etiquette_id\n",
        "\n",
        "def get_previous_etiquette():\n",
        "    \"\"\"R√©cup√®re l'√©tiquette pr√©c√©dente\"\"\"\n",
        "    sources = load_sources()\n",
        "    dernier_termine = sources.get(\"metadata\", {}).get(\"dernier_termine\")\n",
        "\n",
        "    if not dernier_termine:\n",
        "        return None\n",
        "\n",
        "    dernier_termine_str = str(dernier_termine)\n",
        "    return dernier_termine_str\n",
        "\n",
        "def get_previous_session_id():\n",
        "    \"\"\"R√©cup√®re l'ID de session pr√©c√©dent\"\"\"\n",
        "    sources = load_sources()\n",
        "    dernier_termine = sources.get(\"metadata\", {}).get(\"dernier_termine\")\n",
        "\n",
        "    if not dernier_termine:\n",
        "        return 0\n",
        "\n",
        "    dernier_termine_str = str(dernier_termine)\n",
        "    if \"_\" in dernier_termine_str:\n",
        "        try:\n",
        "            return int(dernier_termine_str.split(\"_\")[-1])\n",
        "        except (ValueError, IndexError):\n",
        "            return 0\n",
        "    return 0\n",
        "\n",
        "def get_previous_user():\n",
        "    \"\"\"R√©cup√®re le nom de l'utilisateur pr√©c√©dent\"\"\"\n",
        "    etiquette = get_previous_etiquette()\n",
        "    if not etiquette:\n",
        "        return None\n",
        "\n",
        "    if \"_\" in etiquette:\n",
        "        return etiquette.split(\"_\")[0]\n",
        "    return etiquette\n",
        "\n",
        "# --- T√©l√©chargement Drive ---\n",
        "def download_drive_folder(drive_url, download_path):\n",
        "    \"\"\"T√©l√©charge un dossier Drive\"\"\"\n",
        "    try:\n",
        "        os.makedirs(download_path, exist_ok=True)\n",
        "        gdown.download_folder(drive_url, output=download_path, quiet=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur t√©l√©chargement {drive_url}: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Recherche intelligente de fichiers ---\n",
        "def find_matada_file(base_path, max_depth=2):\n",
        "    \"\"\"Recherche matada.json de mani√®re robuste\"\"\"\n",
        "    candidates = [\n",
        "        os.path.join(base_path, \"matada.json\"),\n",
        "        os.path.join(base_path, \"..\", \"matada.json\"),\n",
        "        os.path.join(base_path, \"lora_model\", \"matada.json\"),\n",
        "        os.path.join(base_path, \"model\", \"matada.json\"),\n",
        "    ]\n",
        "\n",
        "    for path in candidates:\n",
        "        if os.path.exists(path):\n",
        "            return os.path.abspath(path)\n",
        "\n",
        "    # Recherche r√©cursive limit√©e\n",
        "    try:\n",
        "        for root, dirs, files in os.walk(base_path):\n",
        "            depth = root.replace(base_path, '').count(os.sep)\n",
        "            if depth > max_depth:\n",
        "                continue\n",
        "            if \"matada.json\" in files:\n",
        "                return os.path.join(root, \"matada.json\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erreur recherche r√©cursive: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def find_lora_path(base_path, max_depth=3):\n",
        "    \"\"\"Trouve le chemin LoRA avec v√©rifications\"\"\"\n",
        "    candidates = [\n",
        "        os.path.join(base_path, \"lora_model\"),\n",
        "        os.path.join(base_path, \"..\", \"lora_model\"),\n",
        "        os.path.join(SafeConfig.DRIVE_BASE_PATH, user_name, \"lora_model\"),\n",
        "    ]\n",
        "\n",
        "    for path in candidates:\n",
        "        adapter_config = os.path.join(path, \"adapter_config.json\")\n",
        "        if os.path.exists(adapter_config):\n",
        "            print(f\"‚úÖ LoRA trouv√©: {path}\")\n",
        "            return path\n",
        "\n",
        "    # Recherche r√©cursive\n",
        "    try:\n",
        "        for root, dirs, files in os.walk(base_path):\n",
        "            depth = root.replace(base_path, '').count(os.sep)\n",
        "            if depth > max_depth:\n",
        "                continue\n",
        "            if \"lora_model\" in dirs:\n",
        "                candidate = os.path.join(root, \"lora_model\")\n",
        "                if os.path.exists(os.path.join(candidate, \"adapter_config.json\")):\n",
        "                    print(f\"‚úÖ LoRA trouv√© (r√©cursif): {candidate}\")\n",
        "                    return candidate\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erreur recherche LoRA: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def load_matada_smart(source_path):\n",
        "    \"\"\"Charge matada.json avec fallback s√©curis√©\"\"\"\n",
        "    matada_path = find_matada_file(source_path)\n",
        "\n",
        "    if matada_path and os.path.exists(matada_path):\n",
        "        try:\n",
        "            with open(matada_path, 'r', encoding='utf-8') as f:\n",
        "                matada = json.load(f)\n",
        "            print(f\"‚úÖ matada.json charg√©: {matada_path}\")\n",
        "            return matada\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur lecture matada: {e}\")\n",
        "\n",
        "    # Structure par d√©faut s√©curis√©e\n",
        "    default_matada = {\n",
        "        \"covered_examples\": [],\n",
        "        \"coverage_percentage\": 0.0,\n",
        "        \"total_steps\": 0,\n",
        "        \"sessions_completed\": 0,\n",
        "        \"derniere_session\": {\n",
        "            \"user_name\": user_name,\n",
        "            \"user_id\": user_id,\n",
        "            \"steps\": 0,\n",
        "            \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "            \"repetitions\": 0\n",
        "        },\n",
        "        \"historique\": []\n",
        "    }\n",
        "    print(\"‚ÑπÔ∏è Utilisation de matada.json par d√©faut\")\n",
        "    return default_matada\n",
        "\n",
        "# --- Gestion des verrous ---\n",
        "def acquire_lock(source_path):\n",
        "    \"\"\"Acquiert un verrou atomique\"\"\"\n",
        "    lock_path = os.path.join(source_path, \"lock.json\")\n",
        "    os.makedirs(source_path, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(lock_path):\n",
        "        try:\n",
        "            with open(lock_path, 'r', encoding='utf-8') as f:\n",
        "                lock = json.load(f)\n",
        "\n",
        "            lock_time = datetime.fromisoformat(lock[\"since\"])\n",
        "            hours_diff = (datetime.now() - lock_time).total_seconds() / 3600\n",
        "\n",
        "            if hours_diff < SafeConfig.LOCK_TIMEOUT_HOURS:\n",
        "                print(f\"üîí Verrou actif par {lock['locked_by']} depuis {hours_diff:.1f}h\")\n",
        "                return False\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Verrou expir√©, reprise de contr√¥le\")\n",
        "        except Exception:\n",
        "            # Verrou corrompu, on le supprime\n",
        "            try:\n",
        "                os.remove(lock_path)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # Cr√©ation du verrou\n",
        "    lock_data = {\n",
        "        \"locked_by\": user_name,\n",
        "        \"user_id\": user_id,\n",
        "        \"since\": datetime.now().isoformat(),\n",
        "        \"session_steps\": SafeConfig.MAX_STEPS\n",
        "    }\n",
        "\n",
        "    if atomic_write_json(lock_path, lock_data):\n",
        "        print(\"üîì Verrou acquis - session s√©curis√©e\")\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def release_lock(source_path):\n",
        "    \"\"\"Lib√®re le verrou\"\"\"\n",
        "    lock_path = os.path.join(source_path, \"lock.json\")\n",
        "    try:\n",
        "        if os.path.exists(lock_path):\n",
        "            os.remove(lock_path)\n",
        "            print(\"üîì Verrou lib√©r√©\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erreur lib√©ration verrou: {e}\")\n",
        "\n",
        "# --- Gestion dataset ---\n",
        "def get_dataset_slice(matada):\n",
        "    \"\"\"Calcule les portions de dataset √† utiliser\"\"\"\n",
        "    sessions_completed = matada.get(\"sessions_completed\", 0)\n",
        "    total_size = SafeConfig.TOTAL_DATASET_SIZE\n",
        "    examples_per_session = SafeConfig.EXAMPLES_PER_SESSION\n",
        "\n",
        "    start_idx = (sessions_completed * examples_per_session) % total_size\n",
        "    end_idx = start_idx + examples_per_session\n",
        "\n",
        "    ranges = []\n",
        "    if end_idx <= total_size:\n",
        "        ranges.append((start_idx, end_idx))\n",
        "    else:\n",
        "        overflow = end_idx - total_size\n",
        "        ranges.append((start_idx, total_size))\n",
        "        ranges.append((0, overflow))\n",
        "        print(\"üîÑ Recyclage du dataset (wrap-around)\")\n",
        "\n",
        "    # Mise √† jour couverture\n",
        "    covered = set(matada.get(\"covered_examples\", []))\n",
        "    for start, end in ranges:\n",
        "        covered.update(range(start, end))\n",
        "\n",
        "    covered = {i % total_size for i in covered}\n",
        "    coverage_pct = min(len(covered) / max(1, SafeConfig.TARGET_COVERAGE) * 100, 100)\n",
        "\n",
        "    matada[\"covered_examples\"] = sorted(list(covered))\n",
        "    matada[\"coverage_percentage\"] = round(coverage_pct, 1)\n",
        "\n",
        "    print(f\"üìä Couverture: {len(covered)}/{SafeConfig.TARGET_COVERAGE} ({coverage_pct:.1f}%)\")\n",
        "    print(f\"üî∏ Sessions compl√©t√©es: {sessions_completed}\")\n",
        "    print(\"üî∏ Intervalles:\", \", \".join([f\"{s}‚Üí{e}\" for s, e in ranges]))\n",
        "\n",
        "    return ranges\n",
        "\n",
        "# --- Gestion mod√®le ---\n",
        "def load_model_and_tokenizer(source_path):\n",
        "    \"\"\"Charge le mod√®le avec reprise LoRA intelligente\"\"\"\n",
        "    print(\"üß† Chargement du mod√®le...\")\n",
        "\n",
        "    model_path = SafeConfig.BASE_MODEL\n",
        "    lora_path = find_lora_path(source_path)\n",
        "\n",
        "    if lora_path and os.path.exists(os.path.join(lora_path, \"adapter_config.json\")):\n",
        "        print(f\"‚úÖ Reprise LoRA confirm√©e: {lora_path}\")\n",
        "        model_path = lora_path\n",
        "    else:\n",
        "        print(\"üÜï Nouvel apprentissage - mod√®le de base\")\n",
        "\n",
        "    print(f\"üéØ Chargement depuis: {model_path}\")\n",
        "\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=model_path,\n",
        "        max_seq_length=SafeConfig.MAX_SEQ_LENGTH,\n",
        "        dtype=SafeConfig.DTYPE,\n",
        "        load_in_4bit=SafeConfig.LOAD_IN_4BIT,\n",
        "    )\n",
        "\n",
        "    return model, tokenizer, lora_path\n",
        "\n",
        "def setup_lora(model):\n",
        "    \"\"\"Configure l'adaptateur LoRA\"\"\"\n",
        "    from unsloth import FastLanguageModel\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r=32,\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "        ],\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0,\n",
        "        bias=\"none\",\n",
        "        use_gradient_checkpointing=\"unsloth\",\n",
        "        random_state=SafeConfig.SEED,\n",
        "        use_rslora=False,\n",
        "        loftq_config=None,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- M√©tadonn√©es et performances ---\n",
        "def clean_matada(source_path):\n",
        "    \"\"\"Nettoie les m√©tadonn√©es existantes\"\"\"\n",
        "    matada_path = find_matada_file(source_path)\n",
        "    if not matada_path:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(matada_path, 'r', encoding='utf-8') as f:\n",
        "            matada = json.load(f)\n",
        "\n",
        "        cleaned = False\n",
        "\n",
        "        # Nettoyage derni√®re session\n",
        "        derniere_session = matada.get(\"derniere_session\", {})\n",
        "        if isinstance(derniere_session, dict) and \"drive.google.com\" in str(derniere_session.get(\"user_id\", \"\")):\n",
        "            derniere_session[\"user_id\"] = user_id\n",
        "            cleaned = True\n",
        "\n",
        "        # Nettoyage historique\n",
        "        historique = matada.get(\"historique\", [])\n",
        "        for session in historique:\n",
        "            if isinstance(session, dict) and \"drive.google.com\" in str(session.get(\"user_id\", \"\")):\n",
        "                session[\"user_id\"] = user_id\n",
        "                cleaned = True\n",
        "\n",
        "        if cleaned:\n",
        "            atomic_write_json(matada_path, matada)\n",
        "            print(\"‚úÖ matada.json nettoy√©\")\n",
        "\n",
        "        return matada\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur nettoyage matada: {e}\")\n",
        "        return None\n",
        "\n",
        "def update_matada_metadata(matada, source_path):\n",
        "    \"\"\"Met √† jour les m√©tadonn√©es de session\"\"\"\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    derniere_session = matada.get(\"derniere_session\", {})\n",
        "\n",
        "    # V√©rification et nettoyage\n",
        "    if isinstance(derniere_session, dict) and \"drive.google.com\" in str(derniere_session.get(\"user_id\", \"\")):\n",
        "        derniere_session[\"user_id\"] = user_id\n",
        "\n",
        "    # Compaction ou nouvelle session\n",
        "    can_compact = (isinstance(derniere_session, dict) and\n",
        "                   derniere_session.get(\"user_id\") == user_id and\n",
        "                   derniere_session.get(\"date\") == current_date)\n",
        "\n",
        "    if can_compact:\n",
        "        print(\"üîÑ Compaction de session\")\n",
        "        derniere_session[\"steps\"] = derniere_session.get(\"steps\", 0) + SafeConfig.MAX_STEPS\n",
        "        derniere_session[\"repetitions\"] = derniere_session.get(\"repetitions\", 0) + 1\n",
        "    else:\n",
        "        print(\"üÜï Nouvelle session\")\n",
        "        new_session = {\n",
        "            \"user_name\": user_name,\n",
        "            \"user_id\": user_id,\n",
        "            \"steps\": SafeConfig.MAX_STEPS,\n",
        "            \"date\": current_date,\n",
        "            \"repetitions\": 1\n",
        "        }\n",
        "        matada[\"derniere_session\"] = new_session\n",
        "        historique = matada.get(\"historique\", [])\n",
        "        historique.append(new_session)\n",
        "        matada[\"historique\"] = historique[-10:]  # Garde les 10 derni√®res\n",
        "\n",
        "    # M√©triques globales\n",
        "    matada[\"total_steps\"] = matada.get(\"total_steps\", 0) + SafeConfig.MAX_STEPS\n",
        "    matada[\"sessions_completed\"] = matada.get(\"sessions_completed\", 0) + 1\n",
        "\n",
        "    # Sauvegarde\n",
        "    matada_path = find_matada_file(source_path) or os.path.join(source_path, \"matada.json\")\n",
        "    atomic_write_json(matada_path, matada)\n",
        "\n",
        "    print(f\"üìà M√©tadonn√©es mises √† jour - Total: {matada['total_steps']} steps\")\n",
        "    return matada.get(\"coverage_percentage\", 0.0)\n",
        "\n",
        "def update_user_performance(steps_completed, coverage_increase):\n",
        "    \"\"\"Met √† jour le score de performance\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    if user_name not in sources[\"participants\"]:\n",
        "        sources[\"participants\"][user_name] = {\n",
        "            \"user_id\": user_id,\n",
        "            \"drive_url\": None,\n",
        "            \"sessions_completed\": 0,\n",
        "            \"total_steps\": 0,\n",
        "            \"performance_score\": 0.0,\n",
        "            \"last_activity\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    user_data = sources[\"participants\"][user_name]\n",
        "    user_data[\"sessions_completed\"] = user_data.get(\"sessions_completed\", 0) + 1\n",
        "    user_data[\"total_steps\"] = user_data.get(\"total_steps\", 0) + steps_completed\n",
        "    user_data[\"last_activity\"] = datetime.now().isoformat()\n",
        "\n",
        "    # Calcul score\n",
        "    performance_score = (\n",
        "        user_data[\"total_steps\"] * 0.4 +\n",
        "        coverage_increase * 100 * 0.3 +\n",
        "        user_data[\"sessions_completed\"] * 10 * 0.3\n",
        "    )\n",
        "    user_data[\"performance_score\"] = round(performance_score, 2)\n",
        "\n",
        "    # M√©tadonn√©es globales\n",
        "    metadata = sources[\"metadata\"]\n",
        "    metadata[\"total_sessions\"] = metadata.get(\"total_sessions\", 0) + 1\n",
        "    metadata[\"last_training_user\"] = user_name\n",
        "    metadata[\"total_collective_steps\"] = metadata.get(\"total_collective_steps\", 0) + steps_completed\n",
        "\n",
        "    # Meilleur performeur\n",
        "    current_best = metadata.get(\"best_performer\")\n",
        "    if not current_best or user_data[\"performance_score\"] > sources[\"participants\"].get(current_best, {}).get(\"performance_score\", 0):\n",
        "        metadata[\"best_performer\"] = user_name\n",
        "\n",
        "    save_sources(sources)\n",
        "    print(f\"üìä Performance {user_name}: Score {user_data['performance_score']}\")\n",
        "\n",
        "# --- Logique de s√©quence CORRIG√âE ---\n",
        "def should_continue_own_session():\n",
        "    \"\"\"D√©termine si l'utilisateur continue sa propre session\"\"\"\n",
        "    previous_user = get_previous_user()\n",
        "    return previous_user == user_name\n",
        "\n",
        "def find_best_source_corrected():\n",
        "    \"\"\"Version CORRIG√âE de la s√©lection de source\"\"\"\n",
        "    print(\"üîç Recherche s√©quentielle CORRIG√âE...\")\n",
        "\n",
        "    # D√âTERMINER LE TOUR\n",
        "    if should_continue_own_session():\n",
        "        print(\"üîÑ CONTINUATION de votre propre session\")\n",
        "        # Priorit√© : reprendre sa propre session\n",
        "        personal_path = os.path.join(SafeConfig.DRIVE_BASE_PATH, user_name)\n",
        "        if os.path.exists(personal_path):\n",
        "            matada_path = find_matada_file(personal_path)\n",
        "            if matada_path:\n",
        "                try:\n",
        "                    with open(matada_path, 'r', encoding='utf-8') as f:\n",
        "                        matada = json.load(f)\n",
        "                    if matada.get(\"total_steps\", 0) > 0:\n",
        "                        print(\"‚úÖ Session personnelle viable - reprise\")\n",
        "                        return personal_path, user_name\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erreur lecture session personnelle: {e}\")\n",
        "    else:\n",
        "        previous_user = get_previous_user()\n",
        "        if previous_user:\n",
        "            print(f\"üéØ NOUVEAU TOUR pour {user_name} (apr√®s {previous_user})\")\n",
        "        else:\n",
        "            print(f\"üéØ PREMI√àRE SESSION pour {user_name}\")\n",
        "\n",
        "    # STRAT√âGIE DE SOURCE POUR NOUVEAU TOUR\n",
        "    print(\"üîÑ Recherche de la meilleure source disponible...\")\n",
        "\n",
        "    best_source = None\n",
        "    best_owner = None\n",
        "    best_steps = -1\n",
        "\n",
        "    # Combiner MANUAL_SOURCES + sources.json\n",
        "    all_sources = {}\n",
        "\n",
        "    # MANUAL_SOURCES\n",
        "    for participant, drive_url in SafeConfig.MANUAL_SOURCES.items():\n",
        "        all_sources[participant] = {\n",
        "            \"drive_url\": drive_url,\n",
        "            \"source_type\": \"manual\"\n",
        "        }\n",
        "        print(f\"   üìã Source manuelle: {participant}\")\n",
        "\n",
        "    # sources.json\n",
        "    sources_data = load_sources()\n",
        "    for participant, data in sources_data[\"participants\"].items():\n",
        "        if participant not in all_sources and data.get(\"drive_url\"):\n",
        "            all_sources[participant] = {\n",
        "                \"drive_url\": data[\"drive_url\"],\n",
        "                \"source_type\": \"json\"\n",
        "            }\n",
        "            print(f\"   üìã Source JSON: {participant}\")\n",
        "\n",
        "    # √âviter de reprendre sa propre session si c'est un nouveau tour\n",
        "    if user_name in all_sources:\n",
        "        print(f\"   ‚è© Saut de sa propre session (nouveau tour)\")\n",
        "        del all_sources[user_name]\n",
        "\n",
        "    # Tester chaque source\n",
        "    for participant, info in all_sources.items():\n",
        "        drive_url = info[\"drive_url\"]\n",
        "        if not drive_url:\n",
        "            continue\n",
        "\n",
        "        print(f\"   üîÑ Test de {participant}...\")\n",
        "        participant_path = os.path.join(SafeConfig.WORK_DIR, \"sources\", f\"{participant}_{info['source_type']}\")\n",
        "\n",
        "        if download_drive_folder(drive_url, participant_path):\n",
        "            matada_path = find_matada_file(participant_path)\n",
        "\n",
        "            if matada_path:\n",
        "                try:\n",
        "                    with open(matada_path, 'r', encoding='utf-8') as f:\n",
        "                        matada = json.load(f)\n",
        "\n",
        "                    steps = matada.get(\"total_steps\", 0)\n",
        "\n",
        "                    if steps > 0:\n",
        "                        coverage = matada.get(\"coverage_percentage\", 0)\n",
        "                        print(f\"   ‚úÖ {participant}: {steps} steps, {coverage}%\")\n",
        "\n",
        "                        if steps > best_steps:\n",
        "                            best_steps = steps\n",
        "                            best_source = participant_path\n",
        "                            best_owner = participant\n",
        "                    else:\n",
        "                        print(f\"   ‚ö†Ô∏è {participant}: mod√®le vide\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ùå Erreur lecture {participant}: {e}\")\n",
        "            else:\n",
        "                print(f\"   ‚ùå Aucun matada trouv√© pour {participant}\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå T√©l√©chargement √©chou√© pour {participant}\")\n",
        "\n",
        "    if best_source:\n",
        "        print(f\"üéØ MEILLEURE SOURCE: {best_owner} ({best_steps} steps)\")\n",
        "        return best_source, best_owner\n",
        "\n",
        "    # Fallback final : nouvelle session personnelle\n",
        "    print(\"üìÅ Cr√©ation nouvelle session personnelle\")\n",
        "    personal_path = os.path.join(SafeConfig.DRIVE_BASE_PATH, user_name)\n",
        "    os.makedirs(personal_path, exist_ok=True)\n",
        "\n",
        "    # Cr√©er matada.json si n√©cessaire\n",
        "    matada_path = os.path.join(personal_path, \"matada.json\")\n",
        "    if not os.path.exists(matada_path):\n",
        "        initial_matada = {\n",
        "            \"total_steps\": 0,\n",
        "            \"coverage_percentage\": 0.0,\n",
        "            \"covered_examples\": [],\n",
        "            \"sessions_completed\": 0,\n",
        "            \"derniere_session\": {\n",
        "                \"user_name\": user_name,\n",
        "                \"user_id\": user_id,\n",
        "                \"steps\": 0,\n",
        "                \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                \"repetitions\": 0\n",
        "            },\n",
        "            \"historique\": []\n",
        "        }\n",
        "        atomic_write_json(matada_path, initial_matada)\n",
        "        print(\"‚úÖ Nouveau matada.json cr√©√©\")\n",
        "\n",
        "    return personal_path, user_name\n",
        "\n",
        "# --- Sauvegarde ---\n",
        "def save_training_results(model, tokenizer, lora_path, matada, source_owner):\n",
        "    \"\"\"Sauvegarde compl√®te des r√©sultats\"\"\"\n",
        "    print(\"üíæ Sauvegarde des r√©sultats...\")\n",
        "\n",
        "    # Sauvegarde locale\n",
        "    if not lora_path:\n",
        "        lora_path = os.path.join(SafeConfig.WORK_DIR, \"lora_model\")\n",
        "\n",
        "    os.makedirs(lora_path, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        model.save_pretrained(lora_path)\n",
        "        tokenizer.save_pretrained(lora_path)\n",
        "        print(f\"‚úÖ Mod√®le sauvegard√©: {lora_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur sauvegarde mod√®le: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Sauvegarde Drive personnel\n",
        "    personal_folder = os.path.join(SafeConfig.DRIVE_BASE_PATH, user_name)\n",
        "    personal_lora = os.path.join(personal_folder, \"lora_model\")\n",
        "\n",
        "    os.makedirs(personal_folder, exist_ok=True)\n",
        "\n",
        "    # Nettoyage ancien LoRA\n",
        "    if os.path.exists(personal_lora):\n",
        "        try:\n",
        "            shutil.rmtree(personal_lora)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Impossible de nettoyer ancien LoRA: {e}\")\n",
        "\n",
        "    try:\n",
        "        model.save_pretrained(personal_lora)\n",
        "        tokenizer.save_pretrained(personal_lora)\n",
        "\n",
        "        # Sauvegarde matada\n",
        "        atomic_write_json(os.path.join(personal_folder, \"matada.json\"), matada)\n",
        "\n",
        "        # Mise √† jour performances\n",
        "        old_matada = load_matada_smart(lora_path)\n",
        "        coverage_increase = matada.get(\"coverage_percentage\", 0) - old_matada.get(\"coverage_percentage\", 0)\n",
        "        update_user_performance(SafeConfig.MAX_STEPS, coverage_increase)\n",
        "\n",
        "        # √âTIQUETTE - TOUJOURS MIS √Ä JOUR\n",
        "        etiquette_id = update_etiquette(user_name)\n",
        "\n",
        "        # Fichier info\n",
        "        sources = load_sources()\n",
        "        perf_score = sources[\"participants\"][user_name][\"performance_score\"]\n",
        "\n",
        "        info_content = f\"\"\"Participant: {user_name} (ID: {user_id})\n",
        "Derni√®re session: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "√âtiquette: {etiquette_id}\n",
        "Source reprise: {source_owner}\n",
        "Couverture: {matada['coverage_percentage']}%\n",
        "Total Steps: {matada['total_steps']}\n",
        "Sessions compl√©t√©es: {matada['sessions_completed']}\n",
        "Performance Score: {perf_score}\n",
        "\"\"\"\n",
        "        atomic_write_text(os.path.join(personal_folder, \"info.txt\"), info_content)\n",
        "\n",
        "        print(f\"‚úÖ Tous les fichiers sauvegard√©s dans: {personal_folder}\")\n",
        "        return personal_folder\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur sauvegarde Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Fonction principale CORRIG√âE ---\n",
        "def main_corrected():\n",
        "    \"\"\"Fonction principale avec √©tiquette CORRIG√âE\"\"\"\n",
        "    print(\"üöÄ D√©marrage syst√®me collaboratif CORRIG√â...\")\n",
        "    print(f\"üëã Bienvenue {user_name} (ID: {user_id})!\")\n",
        "\n",
        "    # V√©rification des d√©pendances\n",
        "    if not verify_dependencies():\n",
        "        return\n",
        "\n",
        "    # CONTEXTE DE S√âQUENCE\n",
        "    previous_etiquette = get_previous_etiquette()\n",
        "    previous_user = get_previous_user()\n",
        "    previous_id = get_previous_session_id()\n",
        "\n",
        "    if previous_etiquette:\n",
        "        print(f\"üè∑ Session pr√©c√©dente: {previous_etiquette}\")\n",
        "\n",
        "        if previous_user == user_name:\n",
        "            print(\"üîÑ C'est votre tour de CONTINUER votre session\")\n",
        "        else:\n",
        "            print(f\"üîÑ C'est votre tour APR√àS {previous_user}\")\n",
        "    else:\n",
        "        print(\"üéØ Premi√®re session du projet!\")\n",
        "\n",
        "    # S√©lection de source CORRIG√âE\n",
        "    source_path, source_owner = find_best_source_corrected()\n",
        "    print(f\"‚úÖ Source s√©lectionn√©e: {source_owner}\")\n",
        "\n",
        "    # VERROU\n",
        "    if not acquire_lock(source_path):\n",
        "        print(\"‚ùå Impossible d'acqu√©rir le verrou\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Chargement m√©tadonn√©es\n",
        "        matada = clean_matada(source_path) or load_matada_smart(source_path)\n",
        "\n",
        "        # Calcul dataset\n",
        "        print(\"üìä Calcul des portions dataset...\")\n",
        "        ranges = get_dataset_slice(matada)\n",
        "\n",
        "        # Chargement mod√®le\n",
        "        print(\"üß† Chargement du mod√®le...\")\n",
        "        model, tokenizer, lora_path = load_model_and_tokenizer(source_path)\n",
        "        model = setup_lora(model)\n",
        "\n",
        "        # Pr√©paration donn√©es\n",
        "        print(\"üì• Pr√©paration des donn√©es...\")\n",
        "        dataset = prepare_dataset(ranges, tokenizer)\n",
        "\n",
        "        # Configuration entra√Ænement\n",
        "        from transformers import DataCollatorForSeq2Seq\n",
        "        from trl import SFTConfig, SFTTrainer\n",
        "\n",
        "        data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
        "\n",
        "        sft_config = SFTConfig(\n",
        "            per_device_train_batch_size=SafeConfig.PER_DEVICE_BATCH,\n",
        "            gradient_accumulation_steps=SafeConfig.GRAD_ACCUM,\n",
        "            warmup_steps=5,\n",
        "            max_steps=SafeConfig.MAX_STEPS,\n",
        "            learning_rate=SafeConfig.LEARNING_RATE,\n",
        "            logging_steps=1,\n",
        "            optim=\"adamw_8bit\",\n",
        "            weight_decay=0.01,\n",
        "            lr_scheduler_type=\"linear\",\n",
        "            seed=SafeConfig.SEED,\n",
        "            output_dir=lora_path or os.path.join(SafeConfig.WORK_DIR, \"lora_model\"),\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        trainer = SFTTrainer(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            train_dataset=dataset,\n",
        "            dataset_text_field=\"text\",\n",
        "            max_seq_length=SafeConfig.MAX_SEQ_LENGTH,\n",
        "            data_collator=data_collator,\n",
        "            packing=False,\n",
        "            args=sft_config\n",
        "        )\n",
        "\n",
        "        # Entra√Ænement\n",
        "        print(f\"üöÄ D√©but entra√Ænement ({SafeConfig.MAX_STEPS} steps)...\")\n",
        "        trainer_stats = trainer.train()\n",
        "        print(\"‚úÖ Entra√Ænement termin√©!\")\n",
        "\n",
        "        # Sauvegarde et m√©tadonn√©es\n",
        "        coverage = update_matada_metadata(matada, source_path)\n",
        "        personal_folder = save_training_results(model, tokenizer, lora_path, matada, source_owner)\n",
        "\n",
        "        if personal_folder:\n",
        "            print(f\"\\nüéâ Session termin√©e avec succ√®s!\")\n",
        "            print(f\"üìä Progression: {matada['coverage_percentage']}%\")\n",
        "            print(f\"üìà Total steps: {matada['total_steps']}\")\n",
        "\n",
        "            # Classement\n",
        "            sources = load_sources()\n",
        "            print(\"\\nüèÖ CLASSEMENT:\")\n",
        "            sorted_users = sorted(\n",
        "                sources[\"participants\"].items(),\n",
        "                key=lambda x: x[1][\"performance_score\"],\n",
        "                reverse=True\n",
        "            )\n",
        "            for i, (name, data) in enumerate(sorted_users, 1):\n",
        "                marker = \"üëë\" if i == 1 else \"  \"\n",
        "                print(f\"   {marker} {i}. {name}: {data['performance_score']} pts\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Entra√Ænement termin√© mais sauvegarde partielle\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur pendant l'ex√©cution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        release_lock(source_path)\n",
        "\n",
        "# üéØ LANCEMENT\n",
        "if __name__ == \"__main__\":\n",
        "    main_corrected()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu7lXmeuSYtR"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "# Rendre PUBLIC\n",
        "api.update_repo_visibility(\n",
        "    repo_id=\"Gems234/Alisia-7B-it-V1.0\",\n",
        "    private=True,  # ‚Üê Changer √† False pour public\n",
        "    token='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'\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Mod√®le rendu public sur Hugging Face!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BypcESX-CEY9"
      },
      "source": [
        "#l'objectif du code est de nous faire √† atteindre au moins 20% du dataset utiliser dans le code et sa va fonctionner pour tout les autres datasets."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1EpatscTxlXroS1K-Y3FJJ46Szb0cwM1k",
      "authorship_tag": "ABX9TyODuwHdpAAhY3CurC+5wLb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
