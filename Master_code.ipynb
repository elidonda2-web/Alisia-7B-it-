{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwIGSYPRjgtpN4g5Nqq9yd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elidonda2-web/Alisia-7B-it-/blob/main/Master_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_KFNebvdkjM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#l'acces token que tu avais copier, colle sa dans login(\"sa doit etre √† l'int√©rieur\")"
      ],
      "metadata": {
        "id": "tZfkEKTUeBuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"\")"
      ],
      "metadata": {
        "id": "E9HT1SYHeie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Installation des d√©pendances\n",
        "#!pip install -q unsloth torch transformers trl datasets accelerate bitsandbytes\n",
        "!pip install -q gdown\n",
        "\n",
        "# üîß Importations et configuration\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import gdown\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from google.colab import drive\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# =======================\n",
        "# üîπ Configuration Principale\n",
        "# =======================\n",
        "class Config:\n",
        "    # Mod√®le et donn√©es\n",
        "    BASE_MODEL = \"Gems234/Alisia-7B-it-V1.0\"\n",
        "    DATASET_NAME = \"HuggingFaceH4/ultrachat_200k\"\n",
        "\n",
        "    # Objectifs d'entra√Ænement\n",
        "    TOTAL_DATASET_SIZE = 50000\n",
        "    TARGET_COVERAGE = 20000  # 20% de 100k\n",
        "    EXAMPLES_PER_SESSION = 336  # 84 steps √ó 4 grad_accum\n",
        "\n",
        "    # Param√®tres techniques\n",
        "    MAX_SEQ_LENGTH = 2048\n",
        "    LOAD_IN_4BIT = True\n",
        "    DTYPE = None\n",
        "    PER_DEVICE_BATCH = 2\n",
        "    GRAD_ACCUM = 4\n",
        "    MAX_STEPS = 84\n",
        "    LEARNING_RATE = 2e-4\n",
        "    SEED = 3407\n",
        "\n",
        "    # Chemins\n",
        "    WORK_DIR = \"/content/alisia_collab\"\n",
        "    DRIVE_MOUNT = \"/content/drive\"\n",
        "    DRIVE_BASE_PATH = \"/content/drive/MyDrive/Alisia_Collab\"\n",
        "    SOURCES_FILE = \"sources.json\"\n",
        "    LOCK_TIMEOUT_HOURS = 6\n",
        "\n",
        "    # === SOURCES COLLABORATIVES COMPL√àTES ===\n",
        "    MANUAL_SOURCES = {\n",
        "        \"√âlie\":\"https://drive.google.com/drive/folders/1erhDCDQKrDGpSIZ7KFI82cUSaxJy17aS\"\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# üìÅ Montage Google Drive\n",
        "def setup_drive():\n",
        "    \"\"\"Monte Google Drive et cr√©e la structure de dossiers\"\"\"\n",
        "    print(\"üìÅ Montage de Google Drive...\")\n",
        "    drive.mount(config.DRIVE_MOUNT)\n",
        "\n",
        "    # Cr√©er le dossier de base si n√©cessaire\n",
        "    os.makedirs(config.DRIVE_BASE_PATH, exist_ok=True)\n",
        "    print(f\"‚úÖ Drive mont√©: {config.DRIVE_BASE_PATH}\")\n",
        "\n",
        "setup_drive()\n",
        "\n",
        "# üë§ Syst√®me d'identification am√©lior√©\n",
        "def get_user_identity():\n",
        "    \"\"\"Identifie l'utilisateur avec g√©n√©ration d'ID unique\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    print(\"üë§ Syst√®me d'identification collaboratif\")\n",
        "    print(\"1. Nouvel utilisateur\")\n",
        "    print(\"2. Utilisateur existant\")\n",
        "\n",
        "    choice = input(\"Choisissez une option (1 ou 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Nouvel utilisateur\n",
        "        user_name = input(\"Entrez votre nom: \").strip()\n",
        "        user_id = generate_user_id(sources)\n",
        "\n",
        "        # Enregistrer le nouvel utilisateur\n",
        "        if user_name not in sources[\"participants\"]:\n",
        "            sources[\"participants\"][user_name] = {\n",
        "                \"user_id\": user_id,\n",
        "                \"drive_url\": \"\",\n",
        "                \"added_date\": datetime.now().isoformat(),\n",
        "                \"sessions_completed\": 0,\n",
        "                \"total_steps\": 0,\n",
        "                \"last_activity\": datetime.now().isoformat(),\n",
        "                \"performance_score\": 0.0\n",
        "            }\n",
        "            save_sources(sources)\n",
        "            print(f\"‚úÖ Nouvel utilisateur cr√©√©: {user_name} (ID: {user_id})\")\n",
        "        else:\n",
        "            print(\"‚ùå Ce nom existe d√©j√†\")\n",
        "            return get_user_identity()\n",
        "\n",
        "    else:\n",
        "        # Utilisateur existant\n",
        "        user_name = input(\"Entrez votre nom: \").strip()\n",
        "        if user_name in sources[\"participants\"]:\n",
        "            user_id = sources[\"participants\"][user_name][\"user_id\"]\n",
        "            print(f\"‚úÖ Utilisateur reconnu: {user_name} (ID: {user_id})\")\n",
        "        else:\n",
        "            print(\"‚ùå Utilisateur non trouv√©\")\n",
        "            return get_user_identity()\n",
        "\n",
        "    return user_id, user_name\n",
        "\n",
        "def generate_user_id(sources):\n",
        "    \"\"\"G√©n√®re un ID utilisateur unique\"\"\"\n",
        "    existing_ids = [user_data[\"user_id\"] for user_data in sources[\"participants\"].values() if \"user_id\" in user_data]\n",
        "    new_id = str(len(existing_ids) + 1)\n",
        "    while new_id in existing_ids:\n",
        "        new_id = str(int(new_id) + 1)\n",
        "    return new_id\n",
        "\n",
        "user_id, user_name = get_user_identity()"
      ],
      "metadata": {
        "id": "HMDIoqH691iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîó Gestion am√©lior√©e de sources.json\n",
        "def load_sources():\n",
        "    \"\"\"Charge ou initialise le fichier sources.json avec la nouvelle structure\"\"\"\n",
        "    sources_path = os.path.join(config.DRIVE_BASE_PATH, config.SOURCES_FILE)\n",
        "\n",
        "    if os.path.exists(sources_path):\n",
        "        with open(sources_path, \"r\") as f:\n",
        "            sources = json.load(f)\n",
        "\n",
        "        # V√©rifier la structure et migrer si n√©cessaire\n",
        "        sources = migrate_sources_structure(sources)\n",
        "        return sources\n",
        "    else:\n",
        "        # Nouvelle structure avec scores\n",
        "        initial_sources = {\n",
        "            \"participants\": {},\n",
        "            \"metadata\": {\n",
        "                \"created\": datetime.now().isoformat(),\n",
        "                \"total_sessions\": 0,\n",
        "                \"last_training_user\": None,\n",
        "                \"best_performer\": None,\n",
        "                \"total_collective_steps\": 0\n",
        "            },\n",
        "            \"training_rotation\": []\n",
        "        }\n",
        "        save_sources(initial_sources)\n",
        "        print(\"üìÅ Fichier sources.json cr√©√© avec nouvelle structure\")\n",
        "        return initial_sources\n",
        "\n",
        "def save_sources(sources):\n",
        "    \"\"\"Sauvegarde le fichier sources.json\"\"\"\n",
        "    sources_path = os.path.join(config.DRIVE_BASE_PATH, config.SOURCES_FILE)\n",
        "    with open(sources_path, \"w\") as f:\n",
        "        json.dump(sources, f, indent=2)\n",
        "\n",
        "def migrate_sources_structure(sources):\n",
        "    \"\"\"Migre l'ancienne structure vers la nouvelle\"\"\"\n",
        "    print(\"üîÑ Migration automatique de sources.json...\")\n",
        "\n",
        "    if \"participants\" in sources:\n",
        "        for user_name, user_data in sources[\"participants\"].items():\n",
        "            # Ajouter les champs manquants\n",
        "            if \"user_id\" not in user_data:\n",
        "                user_data[\"user_id\"] = generate_user_id(sources)\n",
        "                print(f\"   ‚úÖ ID g√©n√©r√© pour {user_name}: {user_data['user_id']}\")\n",
        "            if \"total_steps\" not in user_data:\n",
        "                user_data[\"total_steps\"] = 0\n",
        "            if \"performance_score\" not in user_data:\n",
        "                user_data[\"performance_score\"] = 0.0\n",
        "            if \"last_activity\" not in user_data:\n",
        "                user_data[\"last_activity\"] = datetime.now().isoformat()\n",
        "\n",
        "    if \"metadata\" not in sources:\n",
        "        sources[\"metadata\"] = {\n",
        "            \"created\": datetime.now().isoformat(),\n",
        "            \"total_sessions\": 0,\n",
        "            \"last_training_user\": None,\n",
        "            \"best_performer\": None,\n",
        "            \"total_collective_steps\": 0\n",
        "        }\n",
        "\n",
        "    if \"training_rotation\" not in sources:\n",
        "        sources[\"training_rotation\"] = []\n",
        "\n",
        "    save_sources(sources)\n",
        "    print(\"‚úÖ Structure de sources.json migr√©e\")\n",
        "    return sources\n",
        "\n",
        "def update_user_performance(user_name, steps_completed, coverage_increase):\n",
        "    \"\"\"Met √† jour le score de performance de l'utilisateur\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    if user_name in sources[\"participants\"]:\n",
        "        user_data = sources[\"participants\"][user_name]\n",
        "        user_data[\"sessions_completed\"] = user_data.get(\"sessions_completed\", 0) + 1\n",
        "        user_data[\"total_steps\"] = user_data.get(\"total_steps\", 0) + steps_completed\n",
        "        user_data[\"last_activity\"] = datetime.now().isoformat()\n",
        "\n",
        "        # Calcul du score de performance (steps + couverture + r√©gularit√©)\n",
        "        performance_score = (\n",
        "            user_data[\"total_steps\"] * 0.4 +  # Poids pour le volume\n",
        "            coverage_increase * 100 * 0.3 +   # Poids pour l'efficacit√©\n",
        "            user_data[\"sessions_completed\"] * 10 * 0.3  # Poids pour la r√©gularit√©\n",
        "        )\n",
        "        user_data[\"performance_score\"] = round(performance_score, 2)\n",
        "\n",
        "        # Mettre √† jour les m√©tadonn√©es globales\n",
        "        sources[\"metadata\"][\"total_sessions\"] += 1\n",
        "        sources[\"metadata\"][\"last_training_user\"] = user_name\n",
        "        sources[\"metadata\"][\"total_collective_steps\"] += steps_completed\n",
        "\n",
        "        # Mettre √† jour le meilleur performeur\n",
        "        current_best = sources[\"metadata\"].get(\"best_performer\")\n",
        "        if not current_best or user_data[\"performance_score\"] > sources[\"participants\"][current_best][\"performance_score\"]:\n",
        "            sources[\"metadata\"][\"best_performer\"] = user_name\n",
        "\n",
        "        # Ajouter √† la rotation d'entra√Ænement\n",
        "        if user_name not in sources[\"training_rotation\"]:\n",
        "            sources[\"training_rotation\"].append(user_name)\n",
        "\n",
        "        save_sources(sources)\n",
        "        print(f\"üìä Performance mise √† jour pour {user_name}: Score {user_data['performance_score']}\")\n",
        "\n",
        "def get_next_trainer():\n",
        "    \"\"\"D√©termine le prochain formateur bas√© sur les performances et la rotation\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    if not sources[\"participants\"]:\n",
        "        return user_name  # Premier utilisateur\n",
        "\n",
        "    # R√©cup√©rer tous les utilisateurs actifs\n",
        "    active_users = [\n",
        "        name for name, data in sources[\"participants\"].items()\n",
        "        if data.get(\"sessions_completed\", 0) > 0\n",
        "    ]\n",
        "\n",
        "    if not active_users:\n",
        "        return user_name\n",
        "\n",
        "    # Strat√©gie: alterner entre les utilisateurs bas√© sur la performance r√©cente\n",
        "    rotation = sources.get(\"training_rotation\", [])\n",
        "\n",
        "    if not rotation:\n",
        "        # Premier entra√Ænement, choisir l'utilisateur avec le score le plus bas pour √©quilibr√©\n",
        "        sorted_users = sorted(active_users, key=lambda x: sources[\"participants\"][x][\"performance_score\"])\n",
        "        return sorted_users[0]\n",
        "\n",
        "    # V√©rifier le dernier formateur\n",
        "    last_trainer = sources[\"metadata\"].get(\"last_training_user\")\n",
        "\n",
        "    if last_trainer == user_name:\n",
        "        # M√™me utilisateur que la derni√®re fois, continuer\n",
        "        return user_name\n",
        "\n",
        "    # Trouver le prochain dans la rotation bas√© sur la performance\n",
        "    performance_scores = {\n",
        "        name: data[\"performance_score\"]\n",
        "        for name, data in sources[\"participants\"].items()\n",
        "        if name in active_users\n",
        "    }\n",
        "\n",
        "    # Donner la priorit√© aux utilisateurs avec moins de sessions r√©centes\n",
        "    if user_name in active_users:\n",
        "        user_sessions = sources[\"participants\"][user_name][\"sessions_completed\"]\n",
        "        avg_sessions = sum(sources[\"participants\"][u][\"sessions_completed\"] for u in active_users) / len(active_users)\n",
        "\n",
        "        if user_sessions < avg_sessions:\n",
        "            return user_name  # Priorit√© aux nouveaux contributeurs\n",
        "\n",
        "    # Sinon, choisir bas√© sur la performance globale\n",
        "    sorted_by_performance = sorted(performance_scores.items(), key=lambda x: x[1])\n",
        "    return sorted_by_performance[0][0]  # Utilisateur avec le score le plus bas\n",
        "\n",
        "def download_drive_folder(drive_url, download_path):\n",
        "    \"\"\"T√©l√©charge DIRECTEMENT depuis l'URL Drive\"\"\"\n",
        "    try:\n",
        "        os.makedirs(download_path, exist_ok=True)\n",
        "        gdown.download_folder(drive_url, output=download_path, quiet=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur t√©l√©chargement: {e}\")\n",
        "        return False\n",
        "\n",
        "# üîß D√©tection Matada Intelligente\n",
        "def find_matada_file(base_path):\n",
        "    \"\"\"Trouve le fichier matada.json dans diff√©rentes structures\"\"\"\n",
        "    print(f\"üîç Recherche de matada.json dans: {base_path}\")\n",
        "\n",
        "    if os.path.exists(base_path):\n",
        "        for root, dirs, files in os.walk(base_path):\n",
        "            depth = root.replace(base_path, '').count(os.sep)\n",
        "            if depth > 2:\n",
        "                continue\n",
        "\n",
        "            if \"matada.json\" in files:\n",
        "                found_path = os.path.join(root, \"matada.json\")\n",
        "                print(f\"‚úÖ matada.json trouv√©: {found_path}\")\n",
        "                return found_path\n",
        "\n",
        "    print(f\"‚ùå matada.json non trouv√© dans: {base_path}\")\n",
        "    return None\n",
        "\n",
        "def load_matada_smart(source_path):\n",
        "    \"\"\"Charge matada.json intelligemment avec fallbacks\"\"\"\n",
        "    print(f\"\\nüìÑ Chargement intelligent des m√©tadonn√©es depuis: {source_path}\")\n",
        "\n",
        "    matada_path = find_matada_file(source_path)\n",
        "\n",
        "    if matada_path and os.path.exists(matada_path):\n",
        "        try:\n",
        "            with open(matada_path, \"r\") as f:\n",
        "                matada = json.load(f)\n",
        "            print(f\"‚úÖ matada.json charg√©: {matada_path}\")\n",
        "            return matada\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur lecture {matada_path}: {e}\")\n",
        "\n",
        "    print(\"‚ö†Ô∏è  Utilisation de matada.json par d√©faut\")\n",
        "    return {\n",
        "        \"covered_examples\": [],\n",
        "        \"coverage_percentage\": 0.0,\n",
        "        \"total_steps\": 0,\n",
        "        \"sessions_completed\": 0,\n",
        "        \"derniere_session\": {\n",
        "            \"user_name\": user_name,\n",
        "            \"user_id\": user_id,\n",
        "            \"steps\": 0,\n",
        "            \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "            \"repetitions\": 0\n",
        "        },\n",
        "        \"historique\": []\n",
        "    }\n",
        "\n",
        "# üîÑ D√©tection intelligente de la meilleure version\n",
        "def find_best_source():\n",
        "    \"\"\"Trouve la source la plus avanc√©e incluant TOUTES les sources manuelles\"\"\"\n",
        "    sources = load_sources()\n",
        "    best_source = None\n",
        "    best_owner = None\n",
        "    best_total_steps = -1\n",
        "    best_coverage = 0\n",
        "\n",
        "    print(\"üîç Analyse de TOUTES les sources disponibles...\")\n",
        "\n",
        "    # === COMBINER TOUTES LES SOURCES ===\n",
        "    all_sources = {}\n",
        "\n",
        "    # 1. Ajouter les sources du fichier sources.json\n",
        "    for participant, info in sources[\"participants\"].items():\n",
        "        all_sources[participant] = info\n",
        "\n",
        "    # 2. Ajouter TOUTES les sources manuelles du code\n",
        "    for participant, drive_url in config.MANUAL_SOURCES.items():\n",
        "        if participant not in all_sources:\n",
        "            all_sources[participant] = {\n",
        "                \"drive_url\": drive_url,\n",
        "                \"user_id\": f\"manual_{participant}\",\n",
        "                \"sessions_completed\": 0,\n",
        "                \"total_steps\": 0,\n",
        "                \"performance_score\": 0.0,\n",
        "                \"added_date\": datetime.now().isoformat()\n",
        "            }\n",
        "            print(f\"   üìç Source manuelle ajout√©e: {participant}\")\n",
        "        else:\n",
        "            # Mettre √† jour l'URL si elle a chang√©\n",
        "            all_sources[participant][\"drive_url\"] = drive_url\n",
        "\n",
        "    print(f\"   üìä Total des sources: {len(all_sources)} participants\")\n",
        "\n",
        "    # 3. Recherche sur TOUTES les sources combin√©es\n",
        "    for participant, info in all_sources.items():\n",
        "        drive_url = info.get(\"drive_url\")\n",
        "        if not drive_url:\n",
        "            print(f\"    ‚ùå Aucune URL Drive trouv√©e pour {participant}\")\n",
        "            continue\n",
        "\n",
        "        participant_path = os.path.join(config.WORK_DIR, \"sources\", participant)\n",
        "        print(f\"  üìÇ V√©rification de {participant}...\")\n",
        "\n",
        "        if download_drive_folder(drive_url, participant_path):\n",
        "            matada = load_matada_smart(participant_path)\n",
        "\n",
        "            if matada and \"total_steps\" in matada:\n",
        "                total_steps = matada.get(\"total_steps\", 0)\n",
        "                coverage = matada.get(\"coverage_percentage\", 0)\n",
        "\n",
        "                print(f\"    üìä {participant}: {total_steps} steps | Couverture: {coverage}%\")\n",
        "\n",
        "                if total_steps > best_total_steps or (total_steps == best_total_steps and coverage > best_coverage):\n",
        "                    best_total_steps = total_steps\n",
        "                    best_coverage = coverage\n",
        "                    best_source = participant_path\n",
        "                    best_owner = participant\n",
        "            else:\n",
        "                print(f\"    ‚ùå Aucun mod√®le valide trouv√© pour {participant}\")\n",
        "        else:\n",
        "            print(f\"    ‚ùå Impossible de t√©l√©charger {participant}\")\n",
        "\n",
        "    if best_source:\n",
        "        print(f\"üéØ MEILLEURE SOURCE: {best_owner} (Steps: {best_total_steps}, Couverture: {best_coverage}%)\")\n",
        "        return best_source, best_owner\n",
        "    else:\n",
        "        print(\"‚ùå Aucune source valide trouv√©e\")\n",
        "        return None, None\n",
        "\n",
        "# üÜï Initialisation am√©lior√©e\n",
        "def initialize_new_user():\n",
        "    \"\"\"Initialise un nouvel utilisateur avec la nouvelle structure\"\"\"\n",
        "    print(\"\\nüÜï Configuration de votre dossier Drive...\")\n",
        "\n",
        "    personal_folder = os.path.join(config.DRIVE_BASE_PATH, user_name)\n",
        "    os.makedirs(personal_folder, exist_ok=True)\n",
        "\n",
        "    print(\"\\nüìÅ COLLEZ VOTRE LIEN DRIVE:\")\n",
        "    print(\"1. Allez sur votre dossier Drive\")\n",
        "    print(\"2. Clic droit ‚Üí 'Partager' ‚Üí 'Copier le lien'\")\n",
        "    print(\"3. Collez le lien COMPLET ci-dessous\")\n",
        "\n",
        "    drive_url = input(\"\\nüîó Collez le lien COMPLET de votre dossier Drive: \").strip()\n",
        "\n",
        "    # Mettre √† jour sources.json avec l'URL\n",
        "    sources = load_sources()\n",
        "    if user_name in sources[\"participants\"]:\n",
        "        sources[\"participants\"][user_name][\"drive_url\"] = drive_url\n",
        "        save_sources(sources)\n",
        "\n",
        "    # Initialiser matada.json\n",
        "    initial_matada = {\n",
        "        \"total_steps\": 0,\n",
        "        \"coverage_percentage\": 0.0,\n",
        "        \"covered_examples\": [],\n",
        "        \"sessions_completed\": 0,\n",
        "        \"derniere_session\": {\n",
        "            \"user_name\": user_name,\n",
        "            \"user_id\": user_id,\n",
        "            \"steps\": 0,\n",
        "            \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "            \"repetitions\": 0\n",
        "        },\n",
        "        \"historique\": []\n",
        "    }\n",
        "\n",
        "    personal_matada_path = os.path.join(personal_folder, \"matada.json\")\n",
        "    with open(personal_matada_path, \"w\") as f:\n",
        "        json.dump(initial_matada, f, indent=2)\n",
        "\n",
        "    personal_lora_path = os.path.join(personal_folder, \"lora_model\")\n",
        "    os.makedirs(personal_lora_path, exist_ok=True)\n",
        "\n",
        "    print(f\"‚úÖ Votre dossier personnel est configur√©: {personal_folder}\")\n",
        "    return personal_folder\n",
        "\n",
        "# üîí Syst√®me de verrou intelligent\n",
        "def check_lock(source_path):\n",
        "    \"\"\"V√©rifie et cr√©e un verrou intelligent\"\"\"\n",
        "    lock_path = os.path.join(source_path, \"lock.json\")\n",
        "\n",
        "    if os.path.exists(lock_path):\n",
        "        with open(lock_path, \"r\") as f:\n",
        "            lock = json.load(f)\n",
        "\n",
        "        lock_time = datetime.fromisoformat(lock[\"since\"])\n",
        "        current_time = datetime.now()\n",
        "        hours_diff = (current_time - lock_time).total_seconds() / 3600\n",
        "\n",
        "        if hours_diff < config.LOCK_TIMEOUT_HOURS:\n",
        "            print(f\"üîí Session verrouill√©e par {lock['locked_by']} (ID: {lock['user_id']}) depuis {hours_diff:.1f}h\")\n",
        "            return False\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Verrou expir√©, reprise de contr√¥le...\")\n",
        "\n",
        "    lock_data = {\n",
        "        \"locked_by\": user_name,\n",
        "        \"user_id\": user_id,\n",
        "        \"since\": datetime.now().isoformat(),\n",
        "        \"session_steps\": config.MAX_STEPS\n",
        "    }\n",
        "\n",
        "    with open(lock_path, \"w\") as f:\n",
        "        json.dump(lock_data, f, indent=2)\n",
        "\n",
        "    print(\"üîì Verrou acquis - session s√©curis√©e\")\n",
        "    return True\n",
        "\n",
        "def remove_lock(source_path):\n",
        "    \"\"\"Supprime le verrou\"\"\"\n",
        "    lock_path = os.path.join(source_path, \"lock.json\")\n",
        "    if os.path.exists(lock_path):\n",
        "        os.remove(lock_path)\n",
        "        print(\"üîì Verrou lib√©r√©\")\n",
        "\n",
        "# üìä Gestion INTELLIGENTE du dataset\n",
        "def get_dataset_slice(matada):\n",
        "    \"\"\"D√©termine quelles portions du dataset utiliser pour cette session\"\"\"\n",
        "    sessions_completed = matada.get(\"sessions_completed\", 0)\n",
        "\n",
        "    start_idx = (sessions_completed * config.EXAMPLES_PER_SESSION) % config.TOTAL_DATASET_SIZE\n",
        "    end_idx = start_idx + config.EXAMPLES_PER_SESSION\n",
        "\n",
        "    ranges = []\n",
        "\n",
        "    if end_idx <= config.TOTAL_DATASET_SIZE:\n",
        "        ranges.append((start_idx, end_idx))\n",
        "    else:\n",
        "        overflow = end_idx - config.TOTAL_DATASET_SIZE\n",
        "        ranges.append((start_idx, config.TOTAL_DATASET_SIZE))\n",
        "        ranges.append((0, overflow))\n",
        "        print(\"üîÑ Recyclage du dataset (wrap-around)\")\n",
        "\n",
        "    covered = set(matada.get(\"covered_examples\", []))\n",
        "    for s, e in ranges:\n",
        "        covered.update(range(s, e))\n",
        "\n",
        "    covered = set(i % config.TOTAL_DATASET_SIZE for i in covered)\n",
        "    coverage_pct = min(len(covered) / max(1, config.TARGET_COVERAGE) * 100, 100)\n",
        "\n",
        "    matada[\"covered_examples\"] = sorted(list(covered))\n",
        "    matada[\"coverage_percentage\"] = round(coverage_pct, 1)\n",
        "\n",
        "    print(f\"üìä Couverture: {len(covered)}/{config.TARGET_COVERAGE} ({coverage_pct:.1f}%)\")\n",
        "    print(f\"üî∏ Sessions compl√©t√©es: {sessions_completed}\")\n",
        "    print(\"üî∏ Intervalles s√©lectionn√©s:\", \", \".join([f\"{s}‚Üí{e}\" for s, e in ranges]))\n",
        "\n",
        "    return ranges\n",
        "\n",
        "def prepare_dataset(ranges, tokenizer):\n",
        "    \"\"\"Charge les tranches de dataset et applique le format de conversation\"\"\"\n",
        "    if not isinstance(ranges, (list, tuple)):\n",
        "        raise ValueError(\"‚ùå 'ranges' doit √™tre une liste de tuples (start, end)\")\n",
        "\n",
        "    loaded_slices = []\n",
        "    for s, e in ranges:\n",
        "        slice_expr = f\"train_sft[{s}:{e}]\"\n",
        "        print(f\"üì• Chargement: {slice_expr\")\n",
        "        ds_part = load_dataset(config.DATASET_NAME, split=slice_expr)\n",
        "        loaded_slices.append(ds_part)\n",
        "\n",
        "    if len(loaded_slices) == 1:\n",
        "        dataset = loaded_slices[0]\n",
        "    else:\n",
        "        dataset = concatenate_datasets(loaded_slices)\n",
        "        print(f\"üîó {len(loaded_slices)} tranches concat√©n√©es -> {len(dataset)} exemples\")\n",
        "\n",
        "    tokenizer.chat_template = \"\"\"<|im_start|>system\n",
        "You are Alisia, a helpful, precise, and knowledgeable assistant created by the Alisia Research Team.<|im_end|>\n",
        "{% for message in messages %}\n",
        "<|im_start|>{{ message['role'] }}\n",
        "{{ message['content'] }}<|im_end|>\n",
        "{% endfor %}\n",
        "{% if add_generation_prompt %}<|im_start|>assistant\n",
        "{% endif %}\"\"\"\n",
        "\n",
        "    def formatting_prompts_func(examples):\n",
        "        conversations = examples[\"messages\"]\n",
        "        texts = [\n",
        "            tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
        "            for convo in conversations\n",
        "        ]\n",
        "        return {\"text\": texts}\n",
        "\n",
        "    dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "    print(f\"‚úÖ Dataset pr√™t pour entra√Ænement : {len(dataset)} exemples\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# üîç Nouvelle fonction : Diagnostic des sources\n",
        "def check_all_sources():\n",
        "    \"\"\"V√©rifie l'accessibilit√© de toutes les sources\"\"\"\n",
        "    print(\"üîç Diagnostic des sources collaboratives...\")\n",
        "    print(f\"üìä {len(config.MANUAL_SOURCES)} participants dans la liste\")\n",
        "\n",
        "    accessible_count = 0\n",
        "    models_found = 0\n",
        "\n",
        "    for participant, drive_url in config.MANUAL_SOURCES.items():\n",
        "        print(f\"\\n  üîó {participant}:\")\n",
        "        print(f\"     üìé {drive_url}\")\n",
        "\n",
        "        test_path = os.path.join(config.WORK_DIR, \"diagnostic\", participant)\n",
        "\n",
        "        if download_drive_folder(drive_url, test_path):\n",
        "            accessible_count += 1\n",
        "            print(f\"     ‚úÖ Accessible\")\n",
        "\n",
        "            # V√©rifier si le dossier contient un mod√®le\n",
        "            matada = load_matada_smart(test_path)\n",
        "            if matada and matada.get(\"total_steps\", 0) > 0:\n",
        "                models_found += 1\n",
        "                print(f\"     ü§ñ Mod√®le trouv√©: {matada.get('total_steps', 0)} steps\")\n",
        "                print(f\"     üìà Couverture: {matada.get('coverage_percentage', 0)}%\")\n",
        "            else:\n",
        "                print(f\"     üìÅ Dossier vide ou sans mod√®le entra√Æn√©\")\n",
        "        else:\n",
        "            print(f\"     ‚ùå Inaccessible\")\n",
        "\n",
        "        # Nettoyer\n",
        "        if os.path.exists(test_path):\n",
        "            shutil.rmtree(test_path)\n",
        "\n",
        "    print(f\"\\nüìã R√âSUM√â DIAGNOSTIC:\")\n",
        "    print(f\"   ‚úÖ {accessible_count}/{len(config.MANUAL_SOURCES)} sources accessibles\")\n",
        "    print(f\"   ü§ñ {models_found} mod√®les entra√Æn√©s trouv√©s\")\n",
        "\n",
        "    return accessible_count, models_found\n",
        "\n",
        "# üß™ Test des sources (ex√©cuter cette ligne apr√®s la cellule)\n",
        "print(\"üöÄ Configuration collaborative pr√™te!\")\n",
        "check_all_sources()"
      ],
      "metadata": {
        "id": "_k4mf3wn97ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Chargement intelligent du mod√®le\n",
        "def load_model_and_tokenizer(source_path):\n",
        "    \"\"\"Charge le mod√®le et tokenizer avec reprise intelligente\"\"\"\n",
        "    model_path = config.BASE_MODEL\n",
        "    lora_path = os.path.join(source_path, \"lora_model\")\n",
        "\n",
        "    if os.path.exists(os.path.join(lora_path, \"adapter_config.json\")):\n",
        "        print(\"üîÑ Reprise depuis le LoRA existant...\")\n",
        "        model_path = lora_path\n",
        "    else:\n",
        "        print(\"üÜï D√©marrage depuis le mod√®le de base...\")\n",
        "\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=model_path,\n",
        "        max_seq_length=config.MAX_SEQ_LENGTH,\n",
        "        dtype=config.DTYPE,\n",
        "        load_in_4bit=config.LOAD_IN_4BIT,\n",
        "    )\n",
        "\n",
        "    return model, tokenizer, lora_path\n",
        "\n",
        "def setup_lora(model):\n",
        "    \"\"\"Configure l'adaptateur LoRA\"\"\"\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r=32,\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "        ],\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0,\n",
        "        bias=\"none\",\n",
        "        use_gradient_checkpointing=\"unsloth\",\n",
        "        random_state=config.SEED,\n",
        "        use_rslora=False,\n",
        "        loftq_config=None,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# üîÑ Mise √† jour CORRIG√âE des m√©tadonn√©es\n",
        "def clean_existing_matada(source_path):\n",
        "    \"\"\"Nettoie les m√©tadonn√©es existantes avec des user_id incorrects\"\"\"\n",
        "    matada_path = find_matada_file(source_path)\n",
        "    if not matada_path:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(matada_path, \"r\") as f:\n",
        "            matada = json.load(f)\n",
        "\n",
        "        cleaned = False\n",
        "        derniere_session = matada.get(\"derniere_session\", {})\n",
        "        if \"drive.google.com\" in str(derniere_session.get(\"user_id\", \"\")):\n",
        "            print(\"üßπ Nettoyage de l'user_id dans derni√®re_session\")\n",
        "            derniere_session[\"user_id\"] = user_id\n",
        "            cleaned = True\n",
        "\n",
        "        history = matada.get(\"historique\", [])\n",
        "        for session in history:\n",
        "            if \"drive.google.com\" in str(session.get(\"user_id\", \"\")):\n",
        "                print(\"üßπ Nettoyage de l'user_id dans l'historique\")\n",
        "                session[\"user_id\"] = user_id\n",
        "                cleaned = True\n",
        "\n",
        "        if cleaned:\n",
        "            with open(matada_path, \"w\") as f:\n",
        "                json.dump(matada, f, indent=2)\n",
        "            print(\"‚úÖ matada.json nettoy√©\")\n",
        "\n",
        "        return matada\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur nettoyage matada: {e}\")\n",
        "        return None\n",
        "\n",
        "def update_matada(matada, source_path):\n",
        "    \"\"\"Met √† jour les m√©tadonn√©es avec validation - VERSION CORRIG√âE\"\"\"\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    derniere_session = matada.get(\"derniere_session\", {})\n",
        "    if \"drive.google.com\" in str(derniere_session.get(\"user_id\", \"\")):\n",
        "        print(\"‚ö†Ô∏è  Nettoyage de l'user_id pr√©c√©dent (contient une URL)\")\n",
        "        derniere_session[\"user_id\"] = user_id\n",
        "\n",
        "    can_compact = (derniere_session.get(\"user_id\") == user_id and\n",
        "                   derniere_session.get(\"date\") == current_date)\n",
        "\n",
        "    if can_compact:\n",
        "        print(\"üîÑ Compaction de session (m√™me jour, m√™me utilisateur)\")\n",
        "        derniere_session[\"steps\"] += config.MAX_STEPS\n",
        "        derniere_session[\"repetitions\"] = derniere_session.get(\"repetitions\", 0) + 1\n",
        "\n",
        "        history = matada.get(\"historique\", [])\n",
        "        for session in history:\n",
        "            if (session.get(\"user_id\") == user_id and\n",
        "                session.get(\"date\") == current_date):\n",
        "                session[\"steps\"] = derniere_session[\"steps\"]\n",
        "                session[\"repetitions\"] = derniere_session[\"repetitions\"]\n",
        "                break\n",
        "    else:\n",
        "        print(\"üÜï Nouvelle session d√©tect√©e\")\n",
        "        new_session = {\n",
        "            \"user_name\": user_name,\n",
        "            \"user_id\": user_id,\n",
        "            \"steps\": config.MAX_STEPS,\n",
        "            \"date\": current_date,\n",
        "            \"repetitions\": 1\n",
        "        }\n",
        "        matada[\"derniere_session\"] = new_session\n",
        "\n",
        "        history = matada.get(\"historique\", [])\n",
        "        history.append(new_session)\n",
        "        matada[\"historique\"] = history[-10:]\n",
        "\n",
        "    # Calcul de l'augmentation de couverture pour le score de performance\n",
        "    old_coverage = matada.get(\"coverage_percentage\", 0)\n",
        "    matada[\"total_steps\"] = matada.get(\"total_steps\", 0) + config.MAX_STEPS\n",
        "    matada[\"sessions_completed\"] = matada.get(\"sessions_completed\", 0) + 1\n",
        "    coverage_increase = matada.get(\"coverage_percentage\", 0) - old_coverage\n",
        "\n",
        "    # Sauvegarde locale\n",
        "    matada_path = find_matada_file(source_path) or os.path.join(source_path, \"matada.json\")\n",
        "    with open(matada_path, \"w\") as f:\n",
        "        json.dump(matada, f, indent=2)\n",
        "\n",
        "    print(f\"üìà M√©tadonn√©es mises √† jour - Total steps: {matada['total_steps']}\")\n",
        "    print(f\"üìÖ Derni√®re session: {matada['derniere_session']['user_name']} - {matada['derniere_session']['steps']} steps\")\n",
        "\n",
        "    return coverage_increase\n",
        "\n",
        "# üíæ SAUVEGARDE CORRIG√âE\n",
        "def save_model_and_tokenizer(model, tokenizer, lora_path):\n",
        "    \"\"\"Sauvegarde le mod√®le et tokenizer\"\"\"\n",
        "    print(\"üíæ Sauvegarde du mod√®le LoRA...\")\n",
        "    model.save_pretrained(lora_path)\n",
        "    tokenizer.save_pretrained(lora_path)\n",
        "    print(f\"‚úÖ Mod√®le sauvegard√© dans: {lora_path}\")\n",
        "    print(f\"‚úÖ Tokenizer sauvegard√© dans: {lora_path}\")\n",
        "\n",
        "def save_to_personal_drive(model, tokenizer, lora_path, matada, source_owner):\n",
        "    \"\"\"Sauvegarde les r√©sultats dans le Drive personnel de l'utilisateur\"\"\"\n",
        "    try:\n",
        "        personal_folder = os.path.join(config.DRIVE_BASE_PATH, user_name)\n",
        "        os.makedirs(personal_folder, exist_ok=True)\n",
        "\n",
        "        personal_lora_path = os.path.join(personal_folder, \"lora_model\")\n",
        "\n",
        "        if os.path.exists(personal_lora_path):\n",
        "            shutil.rmtree(personal_lora_path)\n",
        "\n",
        "        os.makedirs(personal_lora_path, exist_ok=True)\n",
        "\n",
        "        print(\"üíæ Sauvegarde directe dans votre Drive...\")\n",
        "        model.save_pretrained(personal_lora_path)\n",
        "        tokenizer.save_pretrained(personal_lora_path)\n",
        "\n",
        "        print(f\"‚úÖ LoRA sauvegard√© dans: {personal_lora_path}\")\n",
        "\n",
        "        personal_matada_path = os.path.join(personal_folder, \"matada.json\")\n",
        "        with open(personal_matada_path, \"w\") as f:\n",
        "            json.dump(matada, f, indent=2)\n",
        "        print(f\"üìÑ matada.json sauvegard√© dans: {personal_matada_path}\")\n",
        "\n",
        "        # Mettre √† jour les performances dans sources.json\n",
        "        coverage_increase = matada.get(\"coverage_percentage\", 0) - load_matada_smart(lora_path).get(\"coverage_percentage\", 0)\n",
        "        update_user_performance(user_name, config.MAX_STEPS, coverage_increase)\n",
        "\n",
        "        info_content = f\"\"\"Participant: {user_name} (ID: {user_id})\n",
        "Derni√®re session: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "Source reprise: {source_owner}\n",
        "Couverture: {matada['coverage_percentage']}%\n",
        "Total Steps: {matada['total_steps']}\n",
        "Sessions compl√©t√©es: {matada['sessions_completed']}\n",
        "Performance Score: {load_sources()['participants'][user_name]['performance_score']}\n",
        "\"\"\"\n",
        "\n",
        "        info_path = os.path.join(personal_folder, \"info.txt\")\n",
        "        with open(info_path, \"w\") as f:\n",
        "            f.write(info_content)\n",
        "\n",
        "        print(f\"‚úÖ Tous les fichiers sauvegard√©s dans votre Drive personnel: {personal_folder}\")\n",
        "        return personal_folder\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur sauvegarde Drive personnel: {e}\")\n",
        "        return None\n",
        "\n",
        "# üöÄ EX√âCUTION PRINCIPALE AM√âLIOR√âE\n",
        "def main():\n",
        "    print(\"üöÄ D√©marrage du syst√®me collaboratif Alisia...\")\n",
        "    print(f\"üëã Bienvenue {user_name} (ID: {user_id})!\")\n",
        "\n",
        "    # V√©rifier si c'est le tour de cet utilisateur\n",
        "    next_trainer = get_next_trainer()\n",
        "    if next_trainer != user_name:\n",
        "        print(f\"‚è≥ Ce n'est pas encore votre tour. Prochain formateur: {next_trainer}\")\n",
        "        print(\"üìä Scores actuels:\")\n",
        "        sources = load_sources()\n",
        "        for name, data in sources[\"participants\"].items():\n",
        "            print(f\"   {name}: {data['performance_score']} points\")\n",
        "        return\n",
        "\n",
        "    print(\"‚úÖ C'est votre tour de contribuer!\")\n",
        "\n",
        "    print(\"\\nüîç Recherche de la meilleure source...\")\n",
        "    source_path, source_owner = find_best_source()\n",
        "\n",
        "    if not source_path:\n",
        "        print(\"‚ùå Aucune source valide trouv√©e!\")\n",
        "        print(\"üÜï Cr√©ation d'une nouvelle session...\")\n",
        "\n",
        "        source_path = initialize_new_user()\n",
        "        if not source_path:\n",
        "            print(\"‚ùå √âchec de l'initialisation\")\n",
        "            return\n",
        "        source_owner = user_name\n",
        "\n",
        "        matada_path = os.path.join(source_path, \"matada.json\")\n",
        "        with open(matada_path, \"r\") as f:\n",
        "            matada = json.load(f)\n",
        "\n",
        "        print(\"‚úÖ Nouvelle session cr√©√©e!\")\n",
        "    else:\n",
        "        print(\"üßπ V√©rification des m√©tadonn√©es existantes...\")\n",
        "        matada = clean_existing_matada(source_path) or load_matada_smart(source_path)\n",
        "\n",
        "    print(f\"‚úÖ Source s√©lectionn√©e: {source_owner}\")\n",
        "\n",
        "    print(\"\\nüîí V√©rification du verrou...\")\n",
        "    if not check_lock(source_path):\n",
        "        print(\"‚ùå Impossible d'acqu√©rir le verrou - r√©essayez plus tard\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        print(\"\\nüìä Calcul de la portion dataset...\")\n",
        "        ranges = get_dataset_slice(matada)\n",
        "\n",
        "        print(\"\\nüß† Chargement du mod√®le...\")\n",
        "        model, tokenizer, lora_path = load_model_and_tokenizer(source_path)\n",
        "        model = setup_lora(model)\n",
        "\n",
        "        print(\"\\nüì• Pr√©paration des donn√©es...\")\n",
        "        dataset = prepare_dataset(ranges, tokenizer)\n",
        "\n",
        "        print(\"\\n‚öôÔ∏è Configuration de l'entra√Ænement...\")\n",
        "        data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
        "\n",
        "        sft_config = SFTConfig(\n",
        "            per_device_train_batch_size=config.PER_DEVICE_BATCH,\n",
        "            gradient_accumulation_steps=config.GRAD_ACCUM,\n",
        "            warmup_steps=5,\n",
        "            max_steps=config.MAX_STEPS,\n",
        "            learning_rate=config.LEARNING_RATE,\n",
        "            logging_steps=1,\n",
        "            optim=\"adamw_8bit\",\n",
        "            weight_decay=0.01,\n",
        "            lr_scheduler_type=\"linear\",\n",
        "            seed=config.SEED,\n",
        "            output_dir=lora_path,\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        trainer = SFTTrainer(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            train_dataset=dataset,\n",
        "            dataset_text_field=\"text\",\n",
        "            max_seq_length=config.MAX_SEQ_LENGTH,\n",
        "            data_collator=data_collator,\n",
        "            packing=False,\n",
        "            args=sft_config\n",
        "        )\n",
        "\n",
        "        print(f\"\\nüöÄ D√©but de l'entra√Ænement ({config.MAX_STEPS} steps)...\")\n",
        "        trainer_stats = trainer.train()\n",
        "        print(\"‚úÖ Entra√Ænement termin√© avec succ√®s!\")\n",
        "\n",
        "        print(\"\\nüíæ Sauvegarde locale...\")\n",
        "        save_model_and_tokenizer(model, tokenizer, lora_path)\n",
        "\n",
        "        print(\"\\nüìà Mise √† jour des m√©tadonn√©es...\")\n",
        "        coverage_increase = update_matada(matada, source_path)\n",
        "\n",
        "        print(\"\\nüíæ Sauvegarde dans votre Drive personnel...\")\n",
        "        personal_folder = save_to_personal_drive(model, tokenizer, lora_path, matada, source_owner)\n",
        "\n",
        "        if personal_folder:\n",
        "            print(f\"\\nüéâ Session termin√©e avec succ√®s!\")\n",
        "            print(f\"üìä Progression totale: {matada['coverage_percentage']}%\")\n",
        "            print(f\"üìà Total steps cumul√©s: {matada['total_steps']}\")\n",
        "\n",
        "            sources = load_sources()\n",
        "            user_data = sources[\"participants\"][user_name]\n",
        "            print(f\"üèÜ Votre score de performance: {user_data['performance_score']}\")\n",
        "            print(f\"üìÅ Fichiers sauvegard√©s dans: {personal_folder}\")\n",
        "\n",
        "            derniere_session = matada.get(\"derniere_session\", {})\n",
        "            print(f\"üë§ Votre session: {derniere_session.get('steps', 0)} steps\")\n",
        "            if derniere_session.get('repetitions', 1) > 1:\n",
        "                print(f\"üîÑ Sessions compact√©es aujourd'hui: {derniere_session.get('repetitions', 1)}\")\n",
        "\n",
        "            # Afficher le classement\n",
        "            print(\"\\nüèÖ CLASSEMENT DES CONTRIBUTEURS:\")\n",
        "            sorted_users = sorted(sources[\"participants\"].items(), key=lambda x: x[1][\"performance_score\"], reverse=True)\n",
        "            for i, (name, data) in enumerate(sorted_users, 1):\n",
        "                marker = \"üëë\" if i == 1 else \"  \"\n",
        "                print(f\"   {marker} {i}. {name}: {data['performance_score']} points ({data['sessions_completed']} sessions)\")\n",
        "        else:\n",
        "            print(\"‚ùå Erreur lors de la sauvegarde dans Drive\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur pendant l'ex√©cution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        remove_lock(source_path)\n",
        "\n",
        "# üéØ LANCEMENT\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "-3d-Iz7f-Jv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#l'objectif du code est de nous faire √† atteindre au moins 20% du dataset utiliser dans le code et sa va fonctionner pour tout les autres datasets."
      ],
      "metadata": {
        "id": "BypcESX-CEY9"
      }
    }
  ]
}