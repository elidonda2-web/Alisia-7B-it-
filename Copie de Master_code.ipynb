{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1EpatscTxlXroS1K-Y3FJJ46Szb0cwM1k",
      "authorship_tag": "ABX9TyODuwHdpAAhY3CurC+5wLb8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "metadata": {
        "id": "G_KFNebvdkjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acc√®s Token\n",
        "Colle ton token Hugging Face dans la cellule suivante"
      ],
      "metadata": {
        "id": "tZfkEKTUeBuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colle ton token ici\n",
        "# from huggingface_hub import login\n",
        "# login(\"ton_token_ici\")"
      ],
      "metadata": {
        "id": "E9HT1SYHeie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Installation des d√©pendances\n",
        "!pip install -q gdown\n",
        "\n",
        "# üîß Importations et configuration\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import gdown\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from google.colab import drive\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# =======================\n",
        "# üîπ Configuration Principale\n",
        "# =======================\n",
        "class Config:\n",
        "    # Mod√®le et donn√©es\n",
        "    BASE_MODEL = \"Gems234/Alisia-7B-it-V1.0\"\n",
        "    DATASET_NAME = \"HuggingFaceH4/ultrachat_200k\"\n",
        "\n",
        "    # Objectifs d'entra√Ænement\n",
        "    TOTAL_DATASET_SIZE = 50000\n",
        "    TARGET_COVERAGE = 20000  # 20% de 100k\n",
        "    EXAMPLES_PER_SESSION = 336  # 84 steps √ó 4 grad_accum\n",
        "\n",
        "    # Param√®tres techniques\n",
        "    MAX_SEQ_LENGTH = 2048\n",
        "    LOAD_IN_4BIT = True\n",
        "    DTYPE = None\n",
        "    PER_DEVICE_BATCH = 2\n",
        "    GRAD_ACCUM = 4\n",
        "    MAX_STEPS = 84\n",
        "    LEARNING_RATE = 2e-4\n",
        "    SEED = 3407\n",
        "\n",
        "    # Chemins\n",
        "    WORK_DIR = \"/content/alisia_collab\"\n",
        "    DRIVE_MOUNT = \"/content/drive\"\n",
        "    DRIVE_BASE_PATH = \"/content/drive/MyDrive/Alisia_Collab\"\n",
        "    SOURCES_FILE = \"sources.json\"\n",
        "    LOCK_TIMEOUT_HOURS = 6\n",
        "\n",
        "    # Sources collaboratives\n",
        "    MANUAL_SOURCES = {\n",
        "        \"√âlie\": \"https://drive.google.com/drive/folders/1ndS1XHWkcTp57s1wibxYIH4P_KB6elsw\",\n",
        "        \"Jos\": \"https://drive.google.com/drive/folders/1bw9J5goW1GzT1O7MA2vA0_BC-wAiiVGE\"\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# üìÅ Montage Google Drive\n",
        "def setup_drive():\n",
        "    \"\"\"Monte Google Drive et cr√©e la structure de dossiers\"\"\"\n",
        "    drive.mount(config.DRIVE_MOUNT)\n",
        "    os.makedirs(config.DRIVE_BASE_PATH, exist_ok=True)\n",
        "    print(f\"‚úÖ Drive mont√©: {config.DRIVE_BASE_PATH}\")\n",
        "\n",
        "setup_drive()\n",
        "\n",
        "# üîó FONCTION load_sources\n",
        "def load_sources():\n",
        "    \"\"\"Charge ou initialise le fichier sources.json avec la nouvelle structure\"\"\"\n",
        "    sources_path = os.path.join(config.DRIVE_BASE_PATH, config.SOURCES_FILE)\n",
        "\n",
        "    if os.path.exists(sources_path):\n",
        "        with open(sources_path, \"r\") as f:\n",
        "            sources = json.load(f)\n",
        "        sources = migrate_sources_structure(sources)\n",
        "        return sources\n",
        "    else:\n",
        "        # Nouvelle structure avec scores\n",
        "        initial_sources = {\n",
        "            \"participants\": {},\n",
        "            \"metadata\": {\n",
        "                \"created\": datetime.now().isoformat(),\n",
        "                \"total_sessions\": 0,\n",
        "                \"last_training_user\": None,\n",
        "                \"best_performer\": None,\n",
        "                \"total_collective_steps\": 0,\n",
        "                \"dernier_termine\": None,\n",
        "                \"heure_dernier_termine\": None,\n",
        "                \"session_id\": 0\n",
        "            },\n",
        "            \"training_rotation\": []\n",
        "        }\n",
        "        save_sources(initial_sources)\n",
        "        print(\"üìÅ Fichier sources.json cr√©√© avec nouvelle structure\")\n",
        "        return initial_sources\n",
        "\n",
        "def save_sources(sources):\n",
        "    \"\"\"Sauvegarde le fichier sources.json\"\"\"\n",
        "    sources_path = os.path.join(config.DRIVE_BASE_PATH, config.SOURCES_FILE)\n",
        "    with open(sources_path, \"w\") as f:\n",
        "        json.dump(sources, f, indent=2)\n",
        "\n",
        "def migrate_sources_structure(sources):\n",
        "    \"\"\"Migre l'ancienne structure vers la nouvelle\"\"\"\n",
        "    print(\"üîÑ Migration automatique de sources.json...\")\n",
        "\n",
        "    if \"participants\" in sources:\n",
        "        for user_name, user_data in sources[\"participants\"].items():\n",
        "            # Ajouter les champs manquants\n",
        "            if \"user_id\" not in user_data:\n",
        "                user_data[\"user_id\"] = generate_user_id(sources)\n",
        "                print(f\"   ‚úÖ ID g√©n√©r√© pour {user_name}: {user_data['user_id']}\")\n",
        "            if \"total_steps\" not in user_data:\n",
        "                user_data[\"total_steps\"] = 0\n",
        "            if \"performance_score\" not in user_data:\n",
        "                user_data[\"performance_score\"] = 0.0\n",
        "            if \"last_activity\" not in user_data:\n",
        "                user_data[\"last_activity\"] = datetime.now().isoformat()\n",
        "\n",
        "    if \"metadata\" not in sources:\n",
        "        sources[\"metadata\"] = {\n",
        "            \"created\": datetime.now().isoformat(),\n",
        "            \"total_sessions\": 0,\n",
        "            \"last_training_user\": None,\n",
        "            \"best_performer\": None,\n",
        "            \"total_collective_steps\": 0\n",
        "        }\n",
        "\n",
        "    # Ajouter les champs √©tiquette si absents\n",
        "    if \"dernier_termine\" not in sources[\"metadata\"]:\n",
        "        sources[\"metadata\"][\"dernier_termine\"] = None\n",
        "        sources[\"metadata\"][\"heure_dernier_termine\"] = None\n",
        "        sources[\"metadata\"][\"session_id\"] = 0\n",
        "\n",
        "    # Correction : s'assurer que total_collective_steps existe\n",
        "    if \"total_collective_steps\" not in sources[\"metadata\"]:\n",
        "        sources[\"metadata\"][\"total_collective_steps\"] = 0\n",
        "\n",
        "    if \"training_rotation\" not in sources:\n",
        "        sources[\"training_rotation\"] = []\n",
        "\n",
        "    save_sources(sources)\n",
        "    print(\"‚úÖ Structure de sources.json migr√©e\")\n",
        "    return sources\n",
        "\n",
        "def generate_user_id(sources):\n",
        "    \"\"\"G√©n√®re un ID utilisateur unique\"\"\"\n",
        "    existing_ids = [user_data.get(\"user_id\", \"\") for user_data in sources[\"participants\"].values() if user_data.get(\"user_id\")]\n",
        "    new_id = str(len(existing_ids) + 1)\n",
        "    while new_id in existing_ids:\n",
        "        new_id = str(int(new_id) + 1)\n",
        "    return new_id\n",
        "\n",
        "# üë§ Syst√®me d'identification\n",
        "def get_user_identity():\n",
        "    \"\"\"Identifie l'utilisateur avec g√©n√©ration d'ID unique\"\"\"\n",
        "    sources = load_sources()\n",
        "\n",
        "    print(\"üë§ Syst√®me d'identification collaboratif\")\n",
        "    print(\"1. Nouvel utilisateur\")\n",
        "    print(\"2. Utilisateur existant\")\n",
        "\n",
        "    choice = input(\"Choisissez une option (1 ou 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Nouvel utilisateur\n",
        "        user_name = input(\"Entrez votre nom: \").strip()\n",
        "\n",
        "        # V√©rifier si le nom existe d√©j√†\n",
        "        if user_name in sources[\"participants\"]:\n",
        "            print(\"‚ùå Ce nom existe d√©j√†\")\n",
        "            return get_user_identity()\n",
        "\n",
        "        user_id = generate_user_id(sources)\n",
        "\n",
        "        # Enregistrer le nouvel utilisateur\n",
        "        sources[\"participants\"][user_name] = {\n",
        "            \"user_id\": user_id,\n",
        "            \"drive_url\": \"\",\n",
        "            \"added_date\": datetime.now().isoformat(),\n",
        "            \"sessions_completed\": 0,\n",
        "            \"total_steps\": 0,\n",
        "            \"last_activity\": datetime.now().isoformat(),\n",
        "            \"performance_score\": 0.0\n",
        "        }\n",
        "        save_sources(sources)\n",
        "        print(f\"‚úÖ Nouvel utilisateur cr√©√©: {user_name} (ID: {user_id})\")\n",
        "\n",
        "    else:\n",
        "        # Utilisateur existant\n",
        "        user_name = input(\"Entrez votre nom: \").strip()\n",
        "        if user_name in sources[\"participants\"]:\n",
        "            user_data = sources[\"participants\"][user_name]\n",
        "            if \"user_id\" not in user_data:\n",
        "                user_data[\"user_id\"] = generate_user_id(sources)\n",
        "                save_sources(sources)\n",
        "                print(f\"üÜï ID g√©n√©r√© pour {user_name}: {user_data['user_id']}\")\n",
        "\n",
        "            user_id = user_data[\"user_id\"]\n",
        "            print(f\"‚úÖ Utilisateur reconnu: {user_name} (ID: {user_id})\")\n",
        "        else:\n",
        "            print(\"‚ùå Utilisateur non trouv√©\")\n",
        "            return get_user_identity()\n",
        "\n",
        "    return user_id, user_name\n",
        "\n",
        "user_id, user_name = get_user_identity()"
      ],
      "metadata": {
        "id": "HMDIoqH691iY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75d35cd-d4ed-4585-9df8-042dcc04d2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Drive mont√©: /content/drive/MyDrive/Alisia_Collab\n",
            "üîÑ Migration automatique de sources.json...\n",
            "‚úÖ Structure de sources.json migr√©e\n",
            "üë§ Syst√®me d'identification collaboratif\n",
            "1. Nouvel utilisateur\n",
            "2. Utilisateur existant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(ranges, tokenizer):\n",
        "    \"\"\"Charge les tranches de dataset et applique le format de conversation\"\"\"\n",
        "    if not isinstance(ranges, (list, tuple)):\n",
        "        raise ValueError(\"‚ùå 'ranges' doit √™tre une liste de tuples (start, end)\")\n",
        "\n",
        "    loaded_slices = []\n",
        "    for s, e in ranges:\n",
        "        slice_expr = f\"train_sft[{s}:{e}]\"\n",
        "        print(f\"üì• Chargement: {slice_expr}\")\n",
        "        ds_part = load_dataset(config.DATASET_NAME, split=slice_expr)\n",
        "        loaded_slices.append(ds_part)\n",
        "\n",
        "    if len(loaded_slices) == 1:\n",
        "        dataset = loaded_slices[0]\n",
        "    else:\n",
        "        dataset = concatenate_datasets(loaded_slices)\n",
        "        print(f\"üîó {len(loaded_slices)} tranches concat√©n√©es -> {len(dataset)} exemples\")\n",
        "\n",
        "    tokenizer.chat_template = \"\"\"<|im_start|>system\n",
        "You are Alisia, a helpful, precise, and knowledgeable assistant created by the Alisia Research Team.<|im_end|>\n",
        "{% for message in messages %}\n",
        "<|im_start|>{{ message['role'] }}\n",
        "{{ message['content'] }}<|im_end|>\n",
        "{% endfor %}\n",
        "{% if add_generation_prompt %}<|im_start|>assistant\n",
        "{% endif %}\"\"\"\n",
        "\n",
        "    def formatting_prompts_func(examples):\n",
        "        conversations = examples[\"messages\"]\n",
        "        texts = [\n",
        "            tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
        "            for convo in conversations\n",
        "        ]\n",
        "        return {\"text\": texts}\n",
        "\n",
        "    dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "    print(f\"‚úÖ Dataset pr√™t pour entra√Ænement : {len(dataset)} exemples\")\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "XLDg82g9PoFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# SYST√àME COLLABORATIF COMPLET\n",
        "# ============================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import shutil\n",
        "import gdown\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- V√©rifications pr√©alables s√©curis√©es ---\n",
        "def verify_dependencies():\n",
        "    \"\"\"V√©rifie toutes les d√©pendances de mani√®re s√©curis√©e\"\"\"\n",
        "    missing = []\n",
        "\n",
        "    # V√©rification des imports critiques\n",
        "    try:\n",
        "        from unsloth import FastLanguageModel\n",
        "    except ImportError:\n",
        "        missing.append(\"unsloth\")\n",
        "\n",
        "    try:\n",
        "        from trl import SFTConfig, SFTTrainer\n",
        "    except ImportError:\n",
        "        missing.append(\"trl\")\n",
        "\n",
        "    try:\n",
        "        from transformers import DataCollatorForSeq2Seq\n",
        "    except ImportError:\n",
        "        missing.append(\"transformers\")\n",
        "\n",
        "    # V√©rification des fonctions d√©finies\n",
        "    if \"prepare_dataset\" not in globals():\n",
        "        missing.append(\"prepare_dataset (d√©fini en cellule 2)\")\n",
        "\n",
        "    if missing:\n",
        "        print(\"‚ùå D√©pendances manquantes :\")\n",
        "        for m in missing:\n",
        "            print(f\"   - {m}\")\n",
        "        print(\"\\nüì¶ Installation recommand√©e :\")\n",
        "        print(\"!pip install -q unsloth trl transformers bitsandbytes accelerate datasets gdown\")\n",
        "        return False\n",
        "\n",
        "    print(\"‚úÖ Toutes les d√©pendances sont disponibles\")\n",
        "    return True\n",
        "\n",
        "# --- Configuration s√©curis√©e ---\n",
        "class SafeConfig:\n",
        "    \"\"\"Configuration avec valeurs par d√©faut s√©curis√©es\"\"\"\n",
        "    # Chemins\n",
        "    DRIVE_BASE_PATH = getattr(config, 'DRIVE_BASE_PATH', '/content/drive')\n",
        "    WORK_DIR = getattr(config, 'WORK_DIR', '/content')\n",
        "    SOURCES_FILE = getattr(config, 'SOURCES_FILE', 'sources.json')\n",
        "\n",
        "    # Mod√®le\n",
        "    BASE_MODEL = getattr(config, 'BASE_MODEL', 'Gems234/Alisia-7B-it-V1.0')\n",
        "    MAX_SEQ_LENGTH = getattr(config, 'MAX_SEQ_LENGTH', 2048)\n",
        "    DTYPE = getattr(config, 'DTYPE', None)\n",
        "    LOAD_IN_4BIT = getattr(config, 'LOAD_IN_4BIT', True)\n",
        "\n",
        "    # Entra√Ænement\n",
        "    MAX_STEPS = getattr(config, 'MAX_STEPS', 100)\n",
        "    LEARNING_RATE = getattr(config, 'LEARNING_RATE', 2e-4)\n",
        "    PER_DEVICE_BATCH = getattr(config, 'PER_DEVICE_BATCH', 1)\n",
        "    GRAD_ACCUM = getattr(config, 'GRAD_ACCUM', 1)\n",
        "    SEED = getattr(config, 'SEED', 42)\n",
        "\n",
        "    # Dataset\n",
        "    EXAMPLES_PER_SESSION = getattr(config, 'EXAMPLES_PER_SESSION', 100)\n",
        "    TOTAL_DATASET_SIZE = getattr(config, 'TOTAL_DATASET_SIZE', 1000)\n",
        "    TARGET_COVERAGE = getattr(config, 'TARGET_COVERAGE', 1000)\n",
        "\n",
        "    # Verrou\n",
        "    LOCK_TIMEOUT_HOURS = getattr(config, 'LOCK_TIMEOUT_HOURS', 6)\n",
        "\n",
        "    # Sources manuelles (fallback)\n",
        "    MANUAL_SOURCES = getattr(config, 'MANUAL_SOURCES', {})\n",
        "\n",
        "# --- Fonction principale ---\n",
        "def main_corrected():\n",
        "    \"\"\"Fonction principale avec √©tiquette CORRIG√âE\"\"\"\n",
        "    print(\"üöÄ D√©marrage syst√®me collaboratif...\")\n",
        "    print(f\"üëã Bienvenue {user_name} (ID: {user_id})!\")\n",
        "\n",
        "    # V√©rification des d√©pendances\n",
        "    if not verify_dependencies():\n",
        "        return\n",
        "\n",
        "    print(\"‚úÖ Syst√®me pr√™t pour l'entra√Ænement collaboratif\")\n",
        "\n",
        "# üéØ LANCEMENT\n",
        "if __name__ == \"__main__\":\n",
        "    main_corrected()"
      ],
      "metadata": {
        "id": "EH4vRtZfPtEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64160a95-31c4-4beb-f5ef-daf5dac4f0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ D√©marrage syst√®me collaboratif...\n",
            "üëã Bienvenue √âlie (ID: 1)!\n",
            "‚úÖ Toutes les d√©pendances sont disponibles\n",
            "‚úÖ Syst√®me pr√™t pour l'entra√Ænement collaboratif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "# Exemple pour rendre public (√† d√©commenter si besoin)\n",
        "# api.update_repo_visibility(\n",
        "#     repo_id=\"Gems234/Alisia-7B-it-V1.0\",\n",
        "#     private=False,\n",
        "#     token='ton_token_ici'\n",
        "# )\n",
        "\n",
        "print(\"‚úÖ Module Hugging Face charg√©\")"
      ],
      "metadata": {
        "id": "Eu7lXmeuSYtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f30ae8a-6c68-4dfc-8591-646f867cf225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Module Hugging Face charg√©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectif du projet\n",
        "L'objectif est d'atteindre au moins 20% de couverture du dataset UltraChat gr√¢ce √† un syst√®me d'entra√Ænement collaboratif."
      ],
      "metadata": {
        "id": "BypcESX-CEY9"
      }
    }
  ]
}
